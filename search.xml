<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>markdown 示例</title>
    <url>/2022/10/18/markdown-sample/</url>
    <content><![CDATA[1. 斜体和粗体使用 * 和 ** 表示斜体和粗体。
示例：
这是 斜体，这是 粗体。
2. 分级标题使用 === 表示一级标题，使用 — 表示二级标题。
示例：
这是一个一级标题============================这是一个二级标题--------------------------------------------------### 这是一个三级标题

你也可以选择在行首加井号表示不同级别的标题 (H1-H6)，例如：
# H1## H2### H3#### H4##### H5###### H6

3. 外链接使用 [描述](链接地址) 为文字增加外链接。
示例：
这是去往 本人博客 的链接。
4. 无序列表使用 *，+，- 表示无序列表。
示例：

无序列表项 一
无序列表项 二
无序列表项 三

5. 有序列表使用数字和点表示有序列表。
示例：

有序列表项 一
有序列表项 二
有序列表项 三

6. 文字引用使用 &gt; 表示文字引用。
示例：

野火烧不尽，春风吹又生。

7. 行内代码块使用 `代码` 表示行内代码块。
示例：
让我们聊聊 html。
8.  代码块使用 四个缩进空格 表示代码块。
示例：
这是一个代码块，此行左侧有四个不可见的空格。

9.  插入图像使用 ![描述](图片链接地址) 插入图像。
示例：

10. 删除线使用 ~~ 表示删除线。
这是一段错误的文本。
11. 加强的代码块支持四十一种编程语言的语法高亮的显示，行号显示。
非代码示例：
$ sudo apt-get install vim-gnome

Python 示例：
@requires_authorizationdef somefunc(param1='', param2=0):    '''A docstring'''    if param1 &gt; param2: # interesting        print 'Greater'    return (param2 - param1 + 1) or Noneclass SomeClass:    pass&gt;&gt;&gt; message = '''interpreter... prompt'''

JavaScript 示例：
/*** nth element in the fibonacci series.* @param n &gt;= 0* @return the nth element, &gt;= 0.*/function fib(n) {  var a = 1, b = 1;  var tmp;  while (--n &gt;= 0) {    tmp = a;    a += b;    b = tmp;  }  return a;}document.write(fib(10));

12. 表格支持


项目
价格
数量



计算机
$1600
5


手机
$12
12


管线
$1
234


13. Html 标签本站支持在 Markdown 语法中嵌套 Html 标签，譬如，你可以用 Html 写一个纵跨两行的表格：
&lt;table&gt;    &lt;tr&gt;        &lt;th rowspan="2"&gt;值班人员&lt;/th&gt;        &lt;th&gt;星期一&lt;/th&gt;        &lt;th&gt;星期二&lt;/th&gt;        &lt;th&gt;星期三&lt;/th&gt;    &lt;/tr&gt;    &lt;tr&gt;        &lt;td&gt;李强&lt;/td&gt;        &lt;td&gt;张明&lt;/td&gt;        &lt;td&gt;王平&lt;/td&gt;    &lt;/tr&gt;&lt;/table&gt;


    
        值班人员
        星期一
        星期二
        星期三
    
    
        李强
        张明
        王平
    

]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Google AOSP 源码获取</title>
    <url>/2022/10/19/android/aosp-get/</url>
    <content><![CDATA[
AOSP，全称”Android Open Source Project”，中文意为”Android 开放源代码项目”。发起者是谷歌，主要用途是移动设备的系统。

准备工作安装 REPOmkdir ~/binPATH=~/bin:$PATHcurl https://storage.googleapis.com/git-repo-downloads/repo &gt; ~/bin/repo## 如果上述 URL 不可访问，可以用下面的：## curl -sSL  'https://gerrit-googlesource.proxy.ustclug.org/git-repo/+/master/repo?format=TEXT' |base64 -d &gt; ~/bin/repochmod a+x ~/bin/repo

下载每月更新的初始化包由于大陆受到 GFW 的限制，所以直接访问 Google 代码仓库会受到限制，所以这里我们通过 Mirror 镜像加速

这里我们使用 科大源 的镜像仓库第一次同步数据量特别大，如果网络不稳定，中间失败就要从头再来了。所以我们提供了打包的 AOSP 镜像，为一个 tar 包，大约 200G（单文件 200G，注意你的磁盘格式要支持）。这样你 就可以通过 HTTP(S) 的方式下载，该方法支持断点续传。


下载地址

注意！下载完成后请检查 checksum 是否匹配，避免重复操作

下载完成后解压到有 200G 可用空间的分区即可

同步代码设置分支
默认同步 master 分支

可以通过指定版本的方式切换分支
repo init -b android-13.0.0_r11


Android 版本列表 

也可以通过查看分支的方式本地查看版本号
cd .repo/manifestsgit branch -avv


首次切换完成后可能会报错，可以无视，我们只需要检查 manifest 文件查看是否切换成功cat .repo/manifests.git/config
[branch "default"]    remote = origin    merge = refs/heads/android-13.0.0_r11 # 这里原本是 master

同步拉取
通过 repo sync 命令进行同步就可以完成最后的代码拉取

REPO 命令开启本地分支repo start my_branch --all
查看当前分支repo branches
丢弃本地改动repo forall -c git reset --hard
切换分支repo checkout my_branch1
查看文件状态repo status
同步指定的项目repo sync platform/prebuilts/rust

可以通过查看 .repo/manifests/default.xml 文件获取到项目名

其他配置
查看 repo 运行过程中执行的 git 命令export REPO_TRACE=1

]]></content>
      <categories>
        <category>aosp</category>
      </categories>
      <tags>
        <tag>google</tag>
        <tag>android</tag>
        <tag>aosp</tag>
        <tag>repo</tag>
      </tags>
  </entry>
  <entry>
    <title>如何清除 Android Button 中自带的 padding</title>
    <url>/2022/10/19/android/button-without-padding/</url>
    <content><![CDATA[
去除 Android 自带的 padding 效果有两种方式


布局文件中去除
  &lt;Button    android:paddingStart="0dp"    android:paddingLeft="0dp"    android:paddingEnd="0dp"    android:paddingRight="0dp"    android:minHeight="0dp"    android:minWidth="0dp" /&gt;

代码去除
  btn.minimumHeight = 0btn.minimumWidth = 0btn.minWidth = 0btn.minHeight = 0btn.setPadding(0)it.layoutParams = it.layoutParams.apply {    width = -2    height = -2}

]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>widgets</tag>
      </tags>
  </entry>
  <entry>
    <title>修补 Honor Note10 内核</title>
    <url>/2024/12/31/android/honor-note10-kirin970-fix-kernel/</url>
    <content><![CDATA[
本文将以 Honor Note10 作为测试平台，介绍如何修改内核配置，以及如何在 docker 环境下编译内核，最后启用 SELinux 的 permissive 模式。

环境描述
docker-compose version 1.27.4
Ubuntu 18.04.6 LTS
Honor Note10
Model: RVL-AL09
Root: Magisk 28.1
Core: HiSilicon Kirin970
Kernel: 4.9.148
Security Patch: 2019-12-1



准备工作
Kernel Source Code
Huawei Open Source Release Center


Magisk Tools
magiskboot 28.1 [x86_64]


Android NDK
android-ndk-r16-beta1



创建环境
建立工作目录
 mkdir Code_Opensourcemkdir software


将 Kernel Source Code 解压到 Code_Opensource 目录
将 magiskboot 放到到 software/magisk/ 目录
将 Android NDK 解压到 software/android-ndk-r16-beta1/ 目录


创建容器

创建 docker-compose.yml
  version: '3.8'services:  ubuntu:    image: ubuntu:bionic    container_name: bionic    command: tail -f /dev/null    volumes:      - ${PWD}/Code_Opensource:/code:rw      - ${PWD}/software:/software:rw

启动容器
  docker-compose up -d



编译内核
修改内核配置

Code_Opensource/kernel/arch/arm64/configs/merge_kirin970_defconfig
  # CONFIG_SECURITY_SELINUX_DEVELOP is not setCONFIG_SECURITY_SELINUX_DEVELOP=y


编译内核

配置编译环境
# 配置镜像源sed -i 's/http:\/\/archive.ubuntu.com/http:\/\/mirrors.aliyun.com/g' /etc/apt/sources.list# 安装编译依赖sudo apt install -y build-essential dc python# 配置环境变量export PATH=/software/android-ndk-r16-beta1/toolchains/aarch64-linux-android-4.9/prebuilt/linux-x86_64/bin:$PATHexport CROSS_COMPILE=aarch64-linux-android-export ARCH=arm64# CC（GNU Compiler Collection）编译器的彩色输出export GCC_COLORS=auto

查看原始内核信息

获取内核镜像
# 查看内核挂载点adb shell "su -c 'ls -al /dev/block/platform/ff3c0000.ufs/by-name/kernel'"# 备份 kernel 镜像adb shell "su -c 'dd if=/dev/block/xxx of=/sdcard/Download/kernel.img'"# 拉取 kernel 镜像adb pull /sdcard/Download/kernel.img software/magisk/

解包原始内核
cd software/magisk# 解包，同时记录下日志信息./magiskboot unpack -n kernel.img


日志信息
  Parsing boot image: [kernel.img]HEADER_VER      [1]KERNEL_SZ       [15263371]RAMDISK_SZ      [336956]SECOND_SZ       [0]RECOV_DTBO_SZ   [0]OS_VERSION      [9.0.0]OS_PATCH_LEVEL  [2019-12]PAGESIZE        [2048]NAME            []CMDLINE         [loglevel=4 initcall_debug=n page_tracker=on unmovable_isolate1=2:192M,3:224M,4:256M printktimer=0xfff0a000,0x534,0x538 androidboot.selinux=enforcing buildvariant=user]CHECKSUM        [8756a966a7b8957fa7e2742a28355059cd255ab9000000000000000000000000]KERNEL_FMT      [gzip]RAMDISK_FMT     [raw]




编译内核

仔细看注释信息!!!仔细看注释信息!!!仔细看注释信息!!!

mkdir -p /code/outcd /code/kernelmake ARCH=arm64 O=/code/out merge_kirin970_defconfig# 如果下面这条命令失败，可以重新执行或修改 -j 参数make ARCH=arm64 O=/code/out -j32cp -f /code/out/arch/arm64/boot/Image.gz /code/kernel/toolscd /code/kernel/tools# --cmdline 参数使用解包后的 CMDLINE，同时修改 androidboot.selinux=enforcing 为 androidboot.selinux=permissive# --os_patch_level 只能使用 YYYY-MM-DD 格式并且只能等于或大于手机的安全补丁日期./mkbootimg --kernel Image.gz --base 0x0 \--cmdline "loglevel=4 initcall_debug=n page_tracker=on unmovable_isolate1=2:192M,3:224M,4:256M printktimer=0xfff0a000,0x534,0x538 androidboot.selinux=permissive buildvariant=user" \--tags_offset 0x07A00000 --kernel_offset 0x00080000 --ramdisk_offset 0x07C00000 \--header_version 1 --os_version 9 --os_patch_level 2019-12-01 \--output kernel-permissive.img



打包内核cd /software/magiskmv /code/kernel/tools/kernel-permissive.img ././magiskboot repack -n kernel-permissive.imgls new-boot.img -al

刷入内核adb reboot bootloaderfastboot flash kernel new-boot.imgfastboot reboot

启用 SELinuxadb shell "su -c 'setenforce 0'"adb shell "su -c 'getenforce'"
]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>huawei</tag>
        <tag>kernel</tag>
        <tag>make</tag>
        <tag>magisk</tag>
        <tag>root</tag>
        <tag>frida</tag>
        <tag>lsposed</tag>
        <tag>hook</tag>
        <tag>docker</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Android strings.xml 中支持的特殊字符</title>
    <url>/2023/03/13/android/strings/</url>
    <content><![CDATA[
要在 string.xml 中显示特殊符号、如@号冒号等、直接写会显示乱码，必须要改为 ASCII 十进制交换编码书写

编码对照表


编码
字符



@
@


:
:


&nbsp;
(空格)


 
(空格)


!
!


"
“


#
#


$
$


%
%


&amp;
&amp;


'
´


(
(


)
)


*
*


+
+


,
,


-
-


.
.


/
/


:
:


;
;


&lt;
&lt;


=
=


&gt;
&gt;


?
?


@
@


[
[


]
]


^
^


_
_


`
`


{
{


|



}
}


~
~


¡
¡


¢
¢


£
£


¤
¤


¥
¥


¦
¦


§
§


¨
¨


©
©


ª
ª


«
«


¬
¬


­
­


®
®


¯
¯


°
°


±
±


²
²


³
³


´
´


µ
µ


¶
¶


·
•


¸
¸


¹
¹


º
º


»
»


¼
¼


½
½


¾
¾


¿
¿


À
À


Á
Á


Â
Â


Ã
Ã


Ä
Ä


Å
Å


Æ
Æ


Ç
Ç


È
È


É
É


Ê
Ê


Ë
Ë


Ì
Ì


Í
Í


Î
Î


Ï
Ï


Ð
Ð


Ñ
Ñ


Ò
Ò


Ó
Ó


Ô
Ô


Õ
Õ


Ö
Ö


×
×


Ø
Ø


Ù
Ù


Ú
Ú


Û
Û


Ü
Ü


Ý
Ý


Þ
Þ


ß
ß


à
à


á
á


â
â


ã
ã


ä
ä


å
å


æ
æ


ç
ç


è
è


é
é


ê
ê


ë
ë


ì
ì


í
í


î
î


ï
ï


ð
ð


ñ
ñ


ò
ò


ó
ó


ô
ô


õ
õ


ö
ö


÷
÷


ø
ø


ù
ù


ú
ú


û
û


ü
ü


ý
ý


þ
þ


ÿ
ÿ


Ā
Ā


ā
ā


Ă
Ă


ă
ă


Ą
Ą


ą
ą


Ć
Ć


ć
ć


Ĉ
Ĉ


ĉ
ĉ


Ċ
Ċ


ċ
ċ


Č
Č


č
č


Ď
Ď


ď
ď


Đ
Đ


đ
đ


Ē
Ē


ē
ē


Ĕ
Ĕ


ĕ
ĕ


Ė
Ė


ė
ė


Ę
Ę


ę
ę


Ě
Ě


ě
ě


Ĝ
Ĝ


ĝ
ĝ


Ğ
Ğ


ğ
ğ


Ġ
Ġ


ġ
ġ


Ģ
Ģ


ģ
ģ


Ĥ
Ĥ


ĥ
ĥ


Ħ
Ħ


ħ
ħ


Ĩ
Ĩ


ĩ
ĩ


Ī
Ī


ī
ī


Ĭ
Ĭ


ĭ
ĭ


Į
Į


į
į


İ
İ


ı
ı


Ĳ
Ĳ


ĳ
ĳ


Ĵ
Ĵ


ĵ
ĵ


Ķ
Ķ


ķ
ķ


ĸ
ĸ


Ĺ
Ĺ


ĺ
ĺ


Ļ
Ļ


ļ
ļ


Ľ
Ľ


ľ
ľ


Ŀ
Ŀ


ŀ
ŀ


Ł
Ł


ł
ł


Ń
Ń


ń
ń


Ņ
Ņ


ņ
ņ


Ň
Ň


ň
ň


ŉ
ŉ


Ŋ
Ŋ


ŋ
ŋ


Ō
Ō


ō
ō


Ŏ
Ŏ


ŏ
ŏ


Ő
Ő


ő
ő


Œ
Œ


œ
œ


Ŕ
Ŕ


ŕ
ŕ


Ŗ
Ŗ


ŗ
ŗ


Ř
Ř


ř
ř


Ś
Ś


ś
ś


Ŝ
Ŝ


ŝ
ŝ


Ş
Ş


ş
ş


Š
Š


š
š


Ţ
Ţ


ţ
ţ


Ť
Ť


ť
ť


Ŧ
Ŧ


ŧ
ŧ


Ũ
Ũ


ũ
ũ


Ū
Ū


ū
ū


Ŭ
Ŭ


ŭ
ŭ


Ů
Ů


ů
ů


Ű
Ű


ű
ű


Ų
Ų


ų
ų


Ŵ
Ŵ


ŵ
ŵ


Ŷ
Ŷ


ŷ
ŷ


Ÿ
Ÿ


Ź
Ź


ź
ź


Ż
Ż


ż
ż


Ž
Ž


ž
ž


]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>strings</tag>
      </tags>
  </entry>
  <entry>
    <title>2023 年 Apple Developer Enterprise Program 续订审核</title>
    <url>/2023/02/23/apple/2023-apple-developer-enterprise-program/</url>
    <content><![CDATA[
又到了一年一度的 Apple 企业级开发帐号的续费了，随之而来的就是帐号续订资格的审核，这里只能说一句，13事儿真多，审核这种东西真的有用？意思人家搞灰产的会给你在里面填：“噢，亲爱的库克，真是不好意思，我拿着你的资源搞了灰产，请你给我审核通过一下哦~”，此处应有掌声。我只想说给你钱还搞那么多逼事儿，真是恶心死人不偿命。

步骤详解Your Organization
Which best describes your entity? 组织的类型

如实填写


Is this the correct name of your organization? 组织的名称是否正确

Yes


Is this the correct URL for your organization’s website? 组织官网是否正确

Yes


Is this your correct email address? 电子邮件地址是否正确

Yes


Are you an employee of the organization? 你是否为该组织员工

Yes


Do you have the authority to accept legal agreements on behalf of your organization? 你是否有权代为接受法律协议

Yes


重点！！！How many employees does your organization have? 该组织的员工数量

这里必须选择大于 100 人的选项，否则你就会收到 库克 ♂ 你 的邮件！


Briefly describe your organization’s primary industry. 描述该组织的经营范围

如实填写



App Development
Tell us about an app you’ve developed or distributed through the program that’s been used for at least 6 months. Describe the app’s purpose and functionality, and how frequently it’s used. Include the bundle identifier. 告诉我们您通过该计划开发或分发的应用，该应用已使用至少 6 个月。描述应用的用途和功能，以及使用频率。包括捆绑标识符。

如实填写


Who builds your in-house apps? 由谁生成应用程序

Employees


How many employees are on your internal app development team? 开发团队成员数量

1-29


How many enterprise apps have you built or are you currently building? 已构建或正在构建的应用数量

1-9


Do you own the intellectual property rights for all of your in-house apps? 是否拥有所有内部应用程序的知识产权？

Yes


Do you own the source code for all of your in-house apps? 是否拥有所有内部应用程序的源代码？

Yes


Are you currently developing or distributing enterprise apps for macOS? 目前正在开发或分发适用于 macOS 的企业应用程序吗？

Yes



App Distribution and Code Sharing
Do you re-sign compiled apps from other developers to use within your organization? 是否对来自其他开发人员的已编译应用重新签名以在组织内使用？

No


Do you act as an app development contractor for other organizations? 您是否担任其他组织的应用程序开发承包商？

No


Who are your app’s users? 谁是应用的用户？

Employees within your organization


Describe in detail how you distribute your apps to users. 详细描述如何将应用分发给用户

描述分发过程


To how many devices does your organization distribute apps using this program? 您的组织使用此程序向多少台设备分发应用程序？

尽量多



Security and App Testing
What mechanisms have you put in place to ensure your apps can only be installed by your employees and permitted users? 你采取了哪些机制来确保你的应用只能由你的员工和允许的用户安装？

如实填写


Have you ever shared the sign in credentials of the Account Holder with others, including contractors or coworkers? 您是否曾经与其他人（包括承包商或同事）共享帐户持有人的登录凭据？

No


Who has access to the sign in credentials of the Account Holder? 谁有权访问帐户持有人的登录凭据？

Account holders


Who has access to your Enterprise App Distribution Certificates? 谁有权访问您的企业应用分发证书？

Account holders and authorized developers


How do you monitor and control access to your Enterprise App Distribution Certificates? 如何监视和控制对企业应用分发证书的访问？

Enable two-factor authentication, administrator hold, generate P12 to developers


Do you use program resources to test apps before publishing them on the App Store? 在将应用发布到 App Store 之前，您是否使用程序资源来测试它们？

No 因为未发布到AppStore


Does your organization have more than one membership in the Apple Developer Enterprise Program? 您的组织是否在 Apple 开发人员企业计划中拥有多个成员资格？

No


Which of the following uses of the program are necessary for your organization? 您的组织需要以下哪些程序用途？

如实填写



]]></content>
      <categories>
        <category>apple</category>
      </categories>
      <tags>
        <tag>Apple Developer Enterprise Program</tag>
        <tag>内鬼‘蒂姆·库克’</tag>
      </tags>
  </entry>
  <entry>
    <title>Cygwin 自定义主题</title>
    <url>/2023/02/16/cygwin/customize-theme-cygwin/</url>
    <content><![CDATA[
定制一个自己喜欢的主题，展示一些个性化的内容

步骤
官方自带的主题文件在 .oh-my-zsh/themes 目录下，可以通过 omz theme list 命令查看所有可用的主题

先通过 omz theme set {theme_name} 命令设置主题，找到一个最贴切自己喜好的主题

然后可以再查看 .oh-my-zsh/themes 下同名的主题文件，复制到 .oh-my-zsh/custom/themes 目录并改名即可

编辑刚才创建的文件内容，并修改其内部样式直至完美，通过 omz theme set {theme_name} 命令设置自定义主题即可


最后贴一份我自己的主题文件
效果
# clistery @ work in ~ on git:master x [ababa112] [10:09:31] C:0$

cyh.zsh-theme
# Clean, simple, compatible and meaningful.# Tested on Linux, Unix and Windows under ANSI colors.# It is recommended to use with a dark background.# Colors: black, red, green, yellow, *blue, magenta, cyan, and white.## Nov 2022 CListeryRED=$fg[red]YELLOW=$fg[yellow]GREEN=$fg[green]WHITE=$fg[white]BLUE=$fg[blue]RED_BOLD=$fg_bold[red]YELLOW_BOLD=$fg_bold[yellow]GREEN_BOLD=$fg_bold[green]WHITE_BOLD=$fg_bold[white]BLUE_BOLD=$fg_bold[blue]RESET_COLOR=$reset_color# VCSCL_VCS_PROMPT_PREFIX1=" %{$reset_color%}on%{$fg[blue]%} "CL_VCS_PROMPT_PREFIX2=":%{$fg[cyan]%}"CL_VCS_PROMPT_SUFFIX="%{$reset_color%}"CL_VCS_PROMPT_DIRTY=" %{$RED%}x"CL_VCS_PROMPT_CLEAN=" %{$GREEN%}o"# Git infolocal git_info='$(git_prompt_info)$(git_prompt_short_sha)'ZSH_THEME_GIT_PROMPT_PREFIX="${CL_VCS_PROMPT_PREFIX1}git${CL_VCS_PROMPT_PREFIX2}"ZSH_THEME_GIT_PROMPT_SUFFIX="$CL_VCS_PROMPT_SUFFIX"ZSH_THEME_GIT_PROMPT_DIRTY="$CL_VCS_PROMPT_DIRTY"ZSH_THEME_GIT_PROMPT_CLEAN="$CL_VCS_PROMPT_CLEAN"# Format for git_prompt_long_sha() and git_prompt_short_sha()ZSH_THEME_GIT_PROMPT_SHA_BEFORE=" %{$reset_color%}%{$fg[white]%}[%{$YELLOW%}"ZSH_THEME_GIT_PROMPT_SHA_AFTER="%{$fg[white]%}]"# SVN infolocal svn_info='$(svn_prompt_info)'ZSH_THEME_SVN_PROMPT_PREFIX="${CL_VCS_PROMPT_PREFIX1}svn${CL_VCS_PROMPT_PREFIX2}"ZSH_THEME_SVN_PROMPT_SUFFIX="$CL_VCS_PROMPT_SUFFIX"ZSH_THEME_SVN_PROMPT_DIRTY="$CL_VCS_PROMPT_DIRTY"ZSH_THEME_SVN_PROMPT_CLEAN="$CL_VCS_PROMPT_CLEAN"# HG infolocal hg_info='$(cl_hg_prompt_info)'cl_hg_prompt_info() {  # make sure this is a hg dir  if [ -d '.hg' ]; then    echo -n "${CL_VCS_PROMPT_PREFIX1}hg${CL_VCS_PROMPT_PREFIX2}"    echo -n $(hg branch 2&gt;/dev/null)    if [[ "$(hg config oh-my-zsh.hide-dirty 2&gt;/dev/null)" != "1" ]]; then      if [ -n "$(hg status 2&gt;/dev/null)" ]; then        echo -n "$CL_VCS_PROMPT_DIRTY"      else        echo -n "$CL_VCS_PROMPT_CLEAN"      fi    fi    echo -n "$CL_VCS_PROMPT_SUFFIX"  fi}# Virtualenvlocal venv_info='$(virtenv_prompt)'CL_THEME_VIRTUALENV_PROMPT_PREFIX=" %{$GREEN%}"CL_THEME_VIRTUALENV_PROMPT_SUFFIX=" %{$reset_color%}%"virtenv_prompt() {  [[ -n "${VIRTUAL_ENV:-}" ]] || return  echo "${CL_THEME_VIRTUALENV_PROMPT_PREFIX}${VIRTUAL_ENV:t}${CL_THEME_VIRTUALENV_PROMPT_SUFFIX}"}local exit_code="%(?,,C:%{$RED%}%?%{$reset_color%})"# Prompt format:## PRIVILEGES USER @ MACHINE in DIRECTORY on git:BRANCH STATE [SHA] [TIME] C:LAST_EXIT_CODE# $ COMMAND## For example:## % clistery @ work in ~ on git:master x [ababa112] [10:09:31] C:0# $PROMPT="%{$terminfo[bold]$fg[blue]%}#%{$reset_color%} \%(#,%{$bg[yellow]%}%{$fg[black]%}%n%{$reset_color%},%{$fg[cyan]%}%n) \%{$reset_color%}@ \%{$GREEN%}%m \%{$reset_color%}in \%{$terminfo[bold]$YELLOW%}%~%{$reset_color%}\${hg_info}\${git_info}\${svn_info}\${venv_info}\\[%*] $exit_code%{$terminfo[bold]$RED%}$ %{$reset_color%}"

]]></content>
      <categories>
        <category>cygwin</category>
      </categories>
      <tags>
        <tag>cygwin</tag>
        <tag>theme</tag>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Cygwin 创建文件权限问题</title>
    <url>/2023/02/15/cygwin/fstab-error-cygwin/</url>
    <content><![CDATA[
在通过命令行，如：mkdir test 创建一个目录或文件后，通过右键属性打开安全选项卡时，Windows 会提示 test 上的权限顺序不正确，而后可能会导致一些文件权限操作上的异常问题发生

原因Cygwin 的主要目的是通过重新编译，将 POSIX 系统（例如 Linux、BSD，以及其他 Unix 系统）上的软件移植到 Windows 上。
所以 Cygwin 自带的对文件的创建命令同样也是通过移植 POSIX 的方式实现，这一点我们可以通过 cygwin 安装目录下的 /etc/fstab 文件内容得到验证
# This is default anyway:none /cygdrive cygdrive binary,posix=0,user 0 0

解决方案默认情况下，Cygwin 使用文件系统的访问控制列表 (ACL) 来实现真正的 POSIX 权限。
某些 Windows 本地程序或进程可能会创建或修改 ACL，导致 Cygwin 将 POSIX 权限计算为 000。
所以需要将 /etc/fstab 改为如下内容：
none /cygdrive cygdrive binary,noacl,posix=0,user 0 0

使用 noacl 挂载选项，Cygwin 会忽略文件系统 ACL，并且只会根据 DOS 只读属性伪造权限位的子集。
最后关闭所有 Cygwin 及相关进程（或者直接重启系统），打开一个新终端并再次对您的文件执行 ls -l
参考
Cygwin
cygwin-sets-file-permission-to-000

]]></content>
      <categories>
        <category>cygwin</category>
      </categories>
      <tags>
        <tag>cygwin</tag>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>fstab</tag>
      </tags>
  </entry>
  <entry>
    <title>设置 Cygwin</title>
    <url>/2022/11/15/cygwin/setup-cygwin/</url>
    <content><![CDATA[Windows Terminal + CygwinWindows Terminal
命令行：${Cygwin安装目录}\Cygwin.bat启动目录：勾选使用父进程

zsh

vim /etc/passwd

找到你当前用户一行，将末尾改为 /bin/zsh
IntelliJ系列 + CygwinSettings -&gt; Tools -&gt; Terminal -&gt; Application Settings -&gt; Shell path: ${Cygwin安装目录}\Cygwin.bat
VSCode + Cygwin"terminal.integrated.profiles.windows": {    "Cygwin": {        "path": [            "${Cygwin安装目录}\Cygwin.bat"        ],        "icon": "terminal-cmd"    }}
]]></content>
      <categories>
        <category>cygwin</category>
      </categories>
      <tags>
        <tag>cygwin</tag>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Cygwin 设置 HOME 目录</title>
    <url>/2023/02/16/cygwin/setup-home-dir-cygwin/</url>
    <content><![CDATA[
由于 Windows 下复杂的环境问题，通过其他软件结合 Cygwin 打开命令行时，默认的 HOME 目录极有可能出现问题，且新版本 Windows Terminal + Cygwin 在 Windows 资源管理器中右键菜单打开终端时会出现无法直接进入到当前目录的情况

环境Windows Terminal + Cygwin + zsh
步骤
勾选 Windows Terminal 中配置文件 Cygwin 启动目录中的 使用父进程目录


修改 Cygwin.bat，添加以下内容
set _T=%CD%.\zsh --login -i

同时如果不想外部传入 HOME 环境变量可在第一行添加
set HOME=

修改 .zshrc
_T=${_T//\\//}if [[ $_T != "C:/WINDOWS/System32" ]]; then cd "$_T"fi

]]></content>
      <categories>
        <category>cygwin</category>
      </categories>
      <tags>
        <tag>cygwin</tag>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>在 HexoMatery 主题下配置 utteranc 评论插件</title>
    <url>/2022/10/20/blog/hexo-matery-setup-utteranc/</url>
    <content><![CDATA[
HexoMatery 主题没有自带 utteranc 评论插件，当然我们也可以依葫芦画瓢地搞一个上去

先决条件
可以保存 utteranc 评论的公共库
可以提交修改的主题仓库

配置 utteranc 评论库
先跟以往创建 github 仓库的方式一样创建一个公共代码库
安装 utteranc app

将 utteranc 插件添加到主题仓库
创建评论模版 在主题 layout\_partial\ 目录下创建 utterances.ejs 请修改文件中有注释说明的部分为你自己的配置信息
 &lt;div class="card" data-aos="fade-up"&gt;&lt;div id="comment_head"&gt;    &lt;div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;"&gt;        &lt;i class="fas fa-comments fa-fw" aria-hidden="true"&gt;&lt;/i&gt;        &lt;span&gt;评论&lt;/span&gt;    &lt;/div&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt;    $(function() {        if(document.getElementById('contact_plan') !== null){            document.getElementById('comment_head').remove();        }    })&lt;/script&gt;&lt;div id="utterances-container" class="card-content center-align"&gt;    &lt;span class="utterances_loading" style="align-content: center;"&gt;        &lt;i class="fas fa-spinner fa-spin"&gt;&lt;/i&gt;    &lt;/span&gt;    &lt;script type="text/javascript"&gt;        function _checkUtteranc() {            document.getElementsByClassName('utterances').length == 1            ? ($('.utterances_loading').fadeTo(1e3, 0))            : setTimeout(_checkUtteranc, 1000);        }        setTimeout(() =&gt; {            var utterances = document.createElement('script');            utterances.type = 'text/javascript';            utterances.async = true;            utterances.setAttribute('issue-term','title') // 这里我们设置为使用页面标题作为 issue titile，更多的请参阅 utterances 官网            utterances.setAttribute('repo','CListery/hexo-utterances') // 这里设置你自己的 utteranc 评论仓库            utterances.setAttribute('label','comment') // 设置 issue 的标签            $('body').hasClass('DarkMode')            ? (utterances.setAttribute('theme','github-dark'))            : (utterances.setAttribute('theme','github-light')),            utterances.crossorigin = 'anonymous';            utterances.src = 'https://utteranc.es/client.js';            document.getElementById('utterances-container').appendChild(utterances);            _checkUtteranc();        }, 1);    &lt;/script&gt;&lt;/div&gt;&lt;/div&gt;

修改主题模版文件

修改 layout\_partial\post-detail.ejs  在 &lt;% if (theme.gitalk &amp;&amp; theme.gitalk.enable) { %&gt; 上一行添加
  &lt;% if (theme.utterances &amp;&amp; theme.utterances.enable) { %&gt;    &lt;%- partial('_partial/utterances') %&gt;&lt;% } %&gt;

修改 layout\contact.ejs  在 &lt;% if (theme.gitalk &amp;&amp; theme.gitalk.enable) { %&gt; 上一行添加
  &lt;% if (theme.utterances &amp;&amp; theme.utterances.enable) { %&gt;    &lt;%- partial('_partial/utterances') %&gt;&lt;% } %&gt;

修改主题中的 _config.yml  添加以下内容
  utterances:    enable: true




最后以上就完成了 utteranc 评论插件的配置，重启 hexo 服务，不出意外就可以看到了
]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Github Pages</tag>
        <tag>utteranc</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Github Pages 的 hexo 博客搭建</title>
    <url>/2022/10/19/blog/hexo-setup/</url>
    <content><![CDATA[先决条件网站源码库
私有仓库，存放你手写的博客源代码，简称 库1

主题库
私有仓库，存放你自定义的主题代码，将其作为 git submodule 添加到 库1，简称 库2

Github Pages 库(xxx.github.io)
公共库，存放通过前两个仓库生成的网站页面，简称 库3


配置给公共库配置部署密钥
用于 库1 和 库2 的代码编译后自动部署到 库3

生成密钥ssh-keygen -t ed25519 -C "clistery.github.io" # 这里的名字取什么都行

上传密钥到 库3
打开 库3 -&gt; Settings -&gt; Security -&gt; Deploy keys -&gt; 将刚才生成的公钥填到这里面

配置 PAT(Personal Access Token)
用于 Workflow 自动部署是可以对库进行读写


点击 Github 右上角头像 -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens -&gt; Tokens(classic) -&gt; Generate new token (classic)
Note 可以随意填写，最好自己看见能懂就行
Expiration 过期时间，可以选择不过期
Select scopes 中勾选 workflow 和 write:packages
Generate token
然后把生成的 token(ghp_xxxxx) 保存下来备用

创建 Workflow
让 库1 &amp; 库2 生成的代码能自动发布到 库3


打开 库1 -&gt; Action -&gt; New workflow -&gt; Simple workflow -&gt; Configure(或者直接在 库1 的根目录创建 .github/workflows/xxx.yml)
name: Hexo Build &amp; Deploy - Private to Publicon:  push:    branches: [ main ]jobs:  build:    runs-on: ubuntu-latest    steps:    # 检出 库1 &amp; 库2    - name: Checkout    uses: actions/checkout@v3.0.0    with:      token: ${{ secrets.CHK_PAT }} # Personal Access Token，稍后我们会在 库1 中进行配置      submodules: 'true' # 检出 submodule      persist-credentials: false    # 设置 node 环境    - name: Prepare Node env    uses: actions/setup-node@v3    with:      node-version: 16    # 设置 hexo 环境并编译    - name: Hexo    run: |      npm i -g hexo-cli      npm i      hexo clean &amp;&amp; hexo g    # 将生成的文件发布到 库3    - name: Deploy    uses: JamesIves/github-pages-deploy-action@v4.3.3    with:      ssh-key: ${{ secrets.DEPLOY_KEY }} # 部署密钥的私钥，稍后我们会在 库1 中进行配置      repository-name: clistery/clistery.github.io # 库3的名字，格式为 user/repository      branch: main # 发布到库3的 main 分支      folder: public # 库3的类型，公共库      single-commit: true      commit-message: "Deploy by source"

配置 Workflows 变量
打开 库1 -&gt; Settings -&gt; Security -&gt; Secrets -&gt; Actions

配置 CHK_PAT

点击 New repository secret
Name 输入 CHK_PAT
Secret 输入 配置 PAT(Personal Access Token) 时生成的 token
Add secret


配置 DEPLOY_KEY

点击 New repository secret
Name 输入 DEPLOY_KEY
Secret 输入 生成密钥 时生成的私钥
Add secret




最后现在一切配置妥当之后，你就可以向 库1 和 库2 中推送代码，workflow 就会自动将代码部署到 库3 中，不出意外的话就可以在 xxx.github.io 中看到更新了
]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Github Pages</tag>
      </tags>
  </entry>
  <entry>
    <title>优化 docker 镜像构建时需要重复下载 apk</title>
    <url>/2023/10/07/docker/apline-apk-locally/</url>
    <content><![CDATA[
众所周知，如果我们需要在 docker 镜像构建时通过包管理器下载一些软件，那么每次我们在修改 DockerFile 时，都需要重新下载一遍，这样会导致构建时间变长，而且如果我们的网络不是很好，那么下载的过程中还可能会出现失败的情况，这样就会导致构建失败，所以我们需要优化这个过程。

环境
宿主机: 20.04.6 LTS (Focal Fossa)
docker: Docker version 24.0.4, build 3713ee1
docker-compose: docker-compose version 1.27.4, build 40524192
alpine: 3.11.6

示例
这里以 在 Docker 中为 Nginx:alpine 安装模块 为例

在这个 DockerFile 中，我们需要编译 nginx，所以有以下这行命令被执行：
# ...apk add --no-cache --virtual dependency gcc libc-dev make openssl-dev pcre-dev zlib-dev linux-headers \# ...

每次在构建镜像时都会重新下载这些包 gcc libc-dev make openssl-dev pcre-dev zlib-dev linux-headers，每次只要修改的内容在这行命令之前都会重新触发下载，这将大大增加构建时间，也白白浪费带宽。

优化思路

办法很简单，就是将这些包保存到本地，在构建时在使用已经下载完成的包进行安装，整过构建流程就会被加快



获取 apk 包
这里以 gcc libc-dev make openssl-dev pcre-dev zlib-dev linux-headers 为例


进入 alpine 镜像
docker run -it alpine:3.11.6 /bin/sh

将包下载到本地
# 设置镜像源sed -i "s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g" /etc/apk/repositories# 下载包apk fetch --recursive --no-cache gcc libc-dev make openssl-dev pcre-dev zlib-dev linux-headers -o /tmp

下载后的 apk 文件会保存在 /tmp 目录下

将包复制到宿主机
docker cp &lt;containerId&gt;:/tmp /host/path/apk

使用本地 apk 包
修改 DockerFile
# ...COPY /host/path/apk /tmp # 将本地的 apk 复制到镜像中RUN apk add --no-cache --virtual dependency /tmp/*.apk \ # 使用本地的 apk 进行安装# ...

构建镜像
docker build -t nginx:alpine .

到这里，我们就可以发现构建速度已经有了较大的提升


后记总结一下优缺点：

优点

构建速度提升
避免了因为网络问题而导致构建失败
足够灵活，如果我们不需要某个包或需要临时增加某个包，只需要修改本地的 apk 包即可


缺点

需要手动下载 apk 包，并复制到镜像中
需要匹配包的版本和镜像的版本，否则可能会出现不兼容的情况，当然这种情况只需要重新下载即可



当然，不仅仅只有这一种方式，还有其他的方式，比如通过创建一个已经安装好这些包的基础镜像，再通过这个基础镜像进行后续编译，但是这种方式的弊端也比较明显，不够灵活，所以我个人还是更喜欢上面这种方式。
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>alpine</tag>
        <tag>dockerfile</tag>
        <tag>docker image</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Docker 中为 Nginx:alpine 安装模块</title>
    <url>/2023/07/27/docker/apline-nginx-install-module/</url>
    <content><![CDATA[
通过 DockerFile 给基于 nginx:apline 构建的镜像安装 HTTP Echo 模块

环境
宿主机: 20.04.6 LTS (Focal Fossa)
docker: Docker version 24.0.4, build 3713ee1
docker-compose: docker-compose version 1.27.4, build 40524192
nginx: nginx:1.19.1-alpine
nginx-module
HTTP Echo: 0.63



DockerFileFROM nginx:1.19.1-alpine as baseRUN sed -i "s/dl-cdn.alpinelinux.org/mirrors.cernet.edu.cn/g" /etc/apk/repositories;FROM base as buildENV ECHO_NGINX_MODULE_VERSION 0.63RUN sed -i "s/dl-cdn.alpinelinux.org/mirrors.cernet.edu.cn/g" /etc/apk/repositories;RUN NGINX_VER=`nginx -v 2&gt;&amp;1 | cut -d '/' -f 2` \    &amp;&amp; cd /tmp \    &amp;&amp; wget http://nginx.org/download/nginx-${NGINX_VER}.tar.gz -O nginx-${NGINX_VER}.tar.gz \    &amp;&amp; wget https://github.com/openresty/echo-nginx-module/archive/refs/tags/v${ECHO_NGINX_MODULE_VERSION}.tar.gz -O echo-nginx-module-${ECHO_NGINX_MODULE_VERSION}.tar.gz \    &amp;&amp; apk add --no-cache --virtual dependency gcc libc-dev make openssl-dev pcre-dev zlib-dev linux-headers \    &amp;&amp; tar zxf nginx-${NGINX_VER}.tar.gz \    &amp;&amp; tar zxf echo-nginx-module-${ECHO_NGINX_MODULE_VERSION}.tar.gz  \    &amp;&amp; cd nginx-${NGINX_VER} \    &amp;&amp; CONFARGS=$(nginx -V 2&gt;&amp;1 | sed -n -e 's/^configure arguments: //p') \    &amp;&amp; echo $CONFARGS \    &amp;&amp; sh -c "./configure --with-compat ${CONFARGS} --add-dynamic-module=../echo-nginx-module-${ECHO_NGINX_MODULE_VERSION}" \    &amp;&amp; make modules \    &amp;&amp; apk del dependency \    &amp;&amp; rm -rf /var/cache/apk/* \    &amp;&amp; mkdir -p /tmp/objs \    &amp;&amp; cp /tmp/nginx-${NGINX_VER}/objs/*.so /tmp/objs/ \    &amp;&amp; ls /tmp/objs -alFROM baseCOPY --from=build /tmp/objs/ngx_http_echo_module.so /etc/nginx/modulesRUN sed -i '1s/^/load_module \/etc\/nginx\/modules\/ngx_http_echo_module.so;\n/' /etc/nginx/nginx.confWORKDIR /www

更多参考https://nginx.org/en/docs/configure.htmlhttps://www.nginx.com/resources/wiki/modules/
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>alpine</tag>
        <tag>nginx</tag>
        <tag>nginx-module</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次 DockerCompose 配置 22 端口映射遇到的坑</title>
    <url>/2022/11/11/docker/port-22-bug/</url>
    <content><![CDATA[
在一次偶然的机会下触发了一个端口映射的bug

配置docker-compose.yml
version: "3.8"services:    machine:        image: ubuntu:20.04        container_name: "ubuntu_2004"        restart: always        tty: true        ports:            - 9500:80            - 9501:22

乍一看没啥毛病是吧，运行试一下
$ docker-compose upCreating network "ubuntu2_default" with the default driverCreating ubuntu_2004 ... errorERROR: for ubuntu_2004  Cannot create container for service machine: invalid port specification: "570082"ERROR: for machine  Cannot create container for service machine: invalid port specification: "570082"ERROR: Encountered errors while bringing up the project.

这就是 22 端口导致的问题，我们把配置文件的端口改为以下写法就可以解决问题了
ports:    - "9500:80"    - "9501:22"
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>ssh</tag>
        <tag>22-port</tag>
        <tag>bugs</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 ssh 桥接方式连接远程 docker 中的 ubuntu</title>
    <url>/2022/11/11/docker/ssh-bridge/</url>
    <content><![CDATA[
很多时候我们的 docker 环境都不在本地，而通过 ssh 连接远程服务器然后在通过 docker 命令进入容器貌似又有点繁琐，所以直接一步到位搞个跳板可以让我们直接访问到容器

配置容器DockerCompose
配置 docker-compose.yml
  version: "3.8"services:    ccc:        image: ubuntu:20.04        container_name: "ubuntu_2004"        restart: always        tty: true        ports:            - "9500:80"            - "9501:22"

运行
  docker-compose up -d

进入容器
  docker exec -it ubuntu_2004 /bin/bash

安装 openssh-server
  apt update &amp;&amp; apt install openssh-server

配置 ssh 公钥
  mkdir ~/.ssh &amp;&amp; touch ~/.ssh/authorized_keys &amp;&amp; chmod 600 ~/.ssh/authorized_keys

最后将公钥写入到 ~/.ssh/authorized_keys 文件中，就完成了容器配置
本地跳板配置# 远程主机(跳板)Host ubuntu    Port 22    User ubuntu    IdentityFile ~/.ssh/id_rsa# docker 容器Host docker_ubuntu    HostName 0.0.0.0    Port 9501    User root    IdentityFile ~/.ssh/id_rsa    ProxyCommand ssh -q -W %h:%p ubuntu

然后通过 ssh docker_ubuntu 命令就可以直接访问到远程 docker 容器了~
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>ubuntu</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 ssh 连接 docker 中的 dsm</title>
    <url>/2023/12/06/dsm/access-dsm-ssh/</url>
    <content><![CDATA[
之前我们在 在 docker 中安装 DSM 安装了 DSM，现在我们需要通过 ssh 连接到 DSM 中，本文将介绍如何通过 ssh 连接到 DSM 中。

由于 DSM 是搭建在 docker 下的，所以我们要连接到 DSM 大概思路如下

通过 ssh 连接到宿主机
再通过宿主机 ssh 连接本地端口登录到 DSM

有点繁琐，简化一下操作，通过宿主机建立一个 ssh jump server，然后通过 ssh jump server 连接到 DSM，这样一步就完成了登录 DSM
关于 ssh jump server 的搭建流程可以查看这篇博客 通过 ssh 桥接方式连接远程 docker 中的 ubuntu, 这里不再赘述
配置
需要先打开 DSM 的 ssh 服务

打开 DSM 控制面板 -&gt; 终端机和 SNMP -&gt; 终端机 -&gt; 启用 SSH 服务


修改 docker-compose.yml
services:  dsm:    # ...    ports:      - 3456:22

重启 DSM
docker-compose restart dsm

创建 home 目录
因为 ssh 登录后默认会进入到用户的 home 目录，所以我们需要创建一个用户所对应的 home 目录
这一步需要在 DSM 中完成，操作非常简单，只需要安装 Synology Photos 即可，安装完成后会自动创建 home 目录

配置 ssh 公钥
将你的公钥写入到 /var/services/homes/&lt;username&gt;/authorized_keys 文件中
vim /etc/ssh/sshd_config

Match User &lt;username&gt;  AuthorizedKeysFile /var/services/homes/&lt;username&gt;/authorized_keys  PasswordAuthentication no  PubkeyAuthentication yes

修改宿主机 ssh 跳板
这一步可以参考 通过 ssh 桥接方式连接远程 docker 中的 ubuntu 完成
sudo vim /etc/ssh/sshd_config

Match User dsm  AuthorizedKeysFile /home/app/.ssh/authorized_keys  PasswordAuthentication no  PubkeyAuthentication yes

配置客户端 ssh
这一步可以参考 通过 ssh 桥接方式连接远程 docker 中的 ubuntu 完成
vim ~/.ssh/config

Host app HostName &lt;host&gt; Port 22 User dsm IdentityFile ~/.ssh/id_rsaHost docker_dsm  HostName 0.0.0.0  Port 3456  User &lt;username&gt;  IdentityFile ~/.ssh/id_rsa  ProxyCommand ssh -q -W %h:%p app

连接 DSM
ssh docker_dsm

]]></content>
      <categories>
        <category>dsm</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>dsm</tag>
        <tag>virtual dsm</tag>
        <tag>synology dsm</tag>
        <tag>ssh jump server</tag>
      </tags>
  </entry>
  <entry>
    <title>修复 virtual DSM 无法访问网络</title>
    <url>/2023/12/06/dsm/fix-dsm-network-issue/</url>
    <content><![CDATA[
之前我们在 在 docker 中安装 DSM 时，我们在 docker 中安装了一个虚拟的 DSM，但是在安装完成后，我们发现 DSM 可以正常安装套件，但是 NTP 和 邮件通知 等服务都无法正常工作，所以我们需要修复这个问题。

添加 DNS
修改 docker-compose.yml
services:  dsm:    # ...    dns:      - 8.8.8.8      - 1.0.0.1

修改 DSM 网络配置

打开 DSM 控制面板
点击网络
切换到常规选项卡
勾选手动配置 DNS 服务器首选 DNS: 8.8.8.8备选 DNS: 1.0.0.1



重启 DSMdocker-compose restart dsm
]]></content>
      <categories>
        <category>dsm</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>dsm</tag>
        <tag>virtual dsm</tag>
        <tag>synology dsm</tag>
        <tag>network error</tag>
      </tags>
  </entry>
  <entry>
    <title>解决反向代理群晖时客户端IP不正确</title>
    <url>/2025/05/22/dsm/fix-reverse-proxy-dsm-remote-ip/</url>
    <content><![CDATA[
通过 nginx 反向代理群晖流量后导致群晖显示登录 IP 不正确

问题诱因由于外部用作反向代理的 nginx 和 群晖 是通过 docker 容器搭建的，所以对于 nginx 和 群晖 来讲，它们分别是处于 docker 网络环境下的不同虚拟机，所以群晖内部 nginx 自带的 set_real_ip_from 127.0.0.1 配置就无效了
群晖内部 nginx 配置
由于群晖重启后会重置，所以直接修改 /etc/nginx/ 下的文件不是首选

所以通过找寻 nginx 模板文件 /usr/syno/share/nginx/nginx.mustache 发现有以下内容
real_ip_header            X-Forwarded-For;real_ip_recursive         on;set_real_ip_from          127.0.0.1;   ---&gt; 这里就是群晖默认自带的信任IP{{#DSM.trust_proxy}}set_real_ip_from          {{.}};       ---&gt; 通过 DSM.trust_proxy 即可动态配置信任IP{{/DSM.trust_proxy}}

通过查找相关文档 DSM.trust_proxy 可以通过群晖的 控制面板-&gt;安全性-&gt;信任的代理服务器 配置，打开 信任的代理服务器 配置后，直接新增一条 外部代理nginx 的 IP 或 IP段 即可
]]></content>
      <categories>
        <category>dsm</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>dsm</tag>
        <tag>virtual dsm</tag>
        <tag>synology dsm</tag>
        <tag>reverse proxy</tag>
        <tag>remote ip</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Linux 环境下为 DSM 安装软件</title>
    <url>/2023/12/06/dsm/install-pkg-with-entware/</url>
    <content><![CDATA[
之前介绍了如何通过 ssh 连接到 DSM，现在我们需要在 DSM 中安装一些软件，本文将介绍如何在 DSM 中安装软件。

首先需要将 ssh 连接到 DSM 中，具体可以参考 通过 ssh 连接 docker 中的 dsm
安装 Entware
由于 Linux DSM 不同于普通的 Linux 发布版，所以我们不能直接使用 apt 或者 yum 等包管理器来安装软件，所以需要通过 Entware 来安装软件


首先查看平台架构
uname -m

Entware 支持如下几种平台：

armv7
x86
x86_64
armv5
mips
mipsel
armv8/aarch64


创建 Entware 安装目录

确保 /opt 目录可以被操作
stat -c '%a' /opt

如果返回大于等于 600，则可以继续操作

创建 /opt 并挂载
mkdir -p /volume1/@Entware/optrm -rf /optmkdir /optmount -o bind /volume1/@Entware/opt /opt


如果挂载失败，则使用软链接的方式创建目录

ln -s /volume1/@Entware/opt/ /opt


安装 Entware


根据平台架构选择对应的安装命令

armv7
wget -O - https://bin.entware.net/armv7sf-k2.6/installer/generic.sh | sh

x86
wget -O - https://bin.entware.net/x86-k2.6/installer/generic.sh | sh

x86_64
wget -O - https://bin.entware.net/x64-k3.2/installer/generic.sh | sh

armv5
wget -O - https://bin.entware.net/armv5sf-k3.2/installer/generic.sh | sh

mips
wget -O - https://bin.entware.net/mipssf-k3.4/installer/generic.sh | sh

mipsel
wget -O - https://bin.entware.net/mipselsf-k3.4/installer/generic.sh | sh

armv8/aarch64
wget -O - https://bin.entware.net/aarch64-k3.10/installer/generic.sh | sh


EntWare 自启动

使用具有管理员权限的账号登录 DSM

打开控制面板

选择任务计划

新增 &gt; 触发的任务 &gt; 用户定义的脚本

常规

名称：EntWare StartUp
用户账号：root
事件：开机


任务设置

将下面的脚本粘贴到运行命令
#!/bin/sh# Mount EntWaremkdir -p /optmount -o bind /volume1/@Entware/opt /opt/opt/etc/init.d/rc.unslung start# Add EntWare Profile in Global Profileif grep -qF '/opt/etc/profile' /etc/profile; then  echo "Confirmed: EntWare Profile in Global Profile"else  echo "Adding: EntWare Profile in Global Profile"  cat &gt;&gt;/etc/profile &lt;&lt;"EOF"# Load EntWare Profile[ -r "/opt/etc/profile" ] &amp;&amp; . /opt/etc/profileEOFfi# Configure EntWare Mirrorsed -i 's|https\?://bin.entware.net|https://mirrors.bfsu.edu.cn/entware|g' /opt/etc/opkg.conf# Update EntWare List/opt/bin/opkg update




确定

重启 DSM




]]></content>
      <categories>
        <category>dsm</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>dsm</tag>
        <tag>virtual dsm</tag>
        <tag>synology dsm</tag>
        <tag>Linux DSM</tag>
      </tags>
  </entry>
  <entry>
    <title>在 docker 中安装 DSM</title>
    <url>/2023/12/06/dsm/install-with-docker/</url>
    <content><![CDATA[
是的，你没有看错，这篇文章的标题是在 docker 中安装 DSM，而不是在 docker 中安装 DSM，这里的 DSM 是指 Synology DSM，也就是群晖的操作系统，这里我们将在 docker 中安装一个虚拟的 DSM，这样我们就可以在不购买群晖硬件的情况下体验 DSM 的功能了。

环境
宿主机: 20.04.6 LTS (Focal Fossa)
docker: Docker version 24.0.6, build ed223bc
docker compose: Docker Compose version v2.21.0
DSM: 7.2.1-69057-1

配置
创建 docker-compose.yml


更多的配置可以参考 Virtual DSM

version: '3'services:  dsm:    container_name: dsm    image: docker.io/clistery/virtual-dsm:latest    environment:      URL: 'https://cndl.synology.cn/download/DSM/release/7.2.1/69057-1/DSM_VirtualDSM_69057.pat'      DISK_SIZE: '100G'      DISK2_SIZE: '100G'      RAM_SIZE: '4G'      CPU_CORES: '4'    devices:      - /dev/kvm      - /dev/net/tun      - /dev/vhost-net    device_cgroup_rules:      - 'c *:* rwm'    cap_add:      - NET_ADMIN    ports:      - '5000:5000'    volumes:      - ${PWD}/pat:/pat:ro      - ${PWD}/storage/sda1:/storage:rw      - ${PWD}/storage/sda2:/storage2:rw    restart: on-failure    stop_grace_period: 1m


其中镜像 docker.io/clistery/virtual-dsm:latest 是基于 Virtual DSM 构建，在其之上做了一些加速优化，及一些工具配置，也可以直接替换为 vdsm/virtual-dsm:latest。


创建目录


创建 pat 目录
创建 storage 目录


创建完成后的目录结构如下：

.├── docker-compose.yml├── pat└── storage

安装加速（可选）
如果使用的镜像是 virtual-dsm:latest，那么可以跳过这一步。这里我们实际安装的版本是 7.2.1，但是由于 7.2.1 中系统关键文件无法解包，只能先通过 7.0.1 解包出关键文件，再进行 7.2.1 版本的安装


进入 pat 目录

下载 PAT 文件

7.0.1
https://cndl.synology.cn/download/DSM/release/7.0.1/42218/DSM_VirtualDSM_42218.pat

dsm.rd

7.0.1 其中的关键文件，可用于加速安装，非必须，如果不提前准备的话，安装过程中会自动下载

curl -r "65627648-71021835" -sfk -o "DSM_VirtualDSM_42218-dsm.rd" "https://cndl.synology.cn/download/DSM/release/7.0.1/42218/DSM_VirtualDSM_42218.pat"


7.2.1: https://cndl.synology.cn/download/DSM/release/7.2.1/69057-1/DSM_VirtualDSM_69057.pat



链接使用了大陆加速，如果无法下载，将链接中的 cndl.synology.cn 替换为 global.download.synology.com



启动docker-compose up -d

然后就可以打开 docker 日志查看安装进度了，直到看到如下日志，就可以用浏览器通过 :5000 端口访问 docker 容器下的 DSM 了
❯ --------------------------------------------------------❯  You can now login to DSM at port 5000❯ --------------------------------------------------------
]]></content>
      <categories>
        <category>dsm</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>dsm</tag>
        <tag>virtual dsm</tag>
        <tag>synology dsm</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 token 访问 git 仓库</title>
    <url>/2022/10/24/git/token-use/</url>
    <content><![CDATA[
可以在无需增加密钥配置的情况下访问指定的单个或多个仓库

这里我们以 gitlab 为例
创建 access_tokens
创建 access token 的方式有两种
项目级别，只对单个项目生效
帐号级别，对该帐号下的所有项目生效



项目 access token
先进入到指定项目
侧边栏 -&gt; Settings
Access tokens
配置 token 的名称，一般我们以用途为名，便于理解
到期时间如果有需要则设置，不设置则永不过期
权限范围按需设置
创建
将生成的 token 用个记事本保存下来先（离开页面或刷新后 token 都不会再显示了）

帐号级别
右上角头像 -&gt; Preferences
侧边栏 -&gt; Access token
配置 token 的名称，一般我们以用途为名，便于理解
到期时间如果有需要则设置，不设置则永不过期
权限范围按需设置
创建
将生成的 token 用个记事本保存下来先（离开页面或刷新后 token 都不会再显示了）

配置仓库访问
使用 token 创建仓库
  git clone https://oauth2:${token}@xxx.git # 使用刚才创建的 token

将已有仓库改为用 token 访问（同样适用于修改 token）
  git remote rm origin # 先删除掉已有的远端git remote add origin https://oauth2:${token}@xxx.git # 使用刚才创建的 tokengit fetch origin

最后使用 token 配置的仓库，能对远端仓库 pull/push 或其他操作的限制就取决于创建时配置的权限范围
]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>token</tag>
        <tag>gitlab</tag>
        <tag>github</tag>
        <tag>svc</tag>
      </tags>
  </entry>
  <entry>
    <title>修复 Gitlab-CE 仓库检查错误</title>
    <url>/2024/10/30/gitlab-ce/fix-repository-checks-error/</url>
    <content><![CDATA[
某一天在 gitlab 管理员邮箱中收到了 ‘GitLab Admin | One project failed its last repository check’ 的邮件，点开一看有一个仓库的自检过不了，于是有了这篇博客

原因调查
根据文档提示，找到自检的日志文件
/var/log/gitlab/gitlab-rails for Omnibus GitLab installations.
/home/git/gitlab/log for installations from source.

文件内容
E, [2024-10-30T07:24:02.126920 #1053] ERROR -- : path/repository: Could not fsck repository: dangling commit d8e2ebdd41444c2b868d6a321c3246ab6831d351

根据日志信息，看起来是一个 dangling commit 引起的，但是仓库本身并没有这个问题，那很可能是 gitlab 的一些缓存信息出现了问题


解决方案
查找 path/repository 仓库在服务器上的文件路径，这里引用官方的文档

在左侧栏的底部，选择 Admin 。
选择 概览 &gt; 项目，选择项目。
定位 相对路径 字段。取值类似于："@hashed/0b/91/0b91...f9.git"


找到项目文件路径后，我们就可以进行修复了

为避免出现不可控的情况，请确保已经对 gitlab 备份


切换到 git 用户
 su - git

执行检查(这一步出现 error 不用理会)

将之前找到的项目文件路径替换到命令中

 /opt/gitlab/embedded/bin/git \-C /var/opt/gitlab/git-data/repositories/@hashed/0b/91/0b91...f9.git fsck

清理缓存
 /opt/gitlab/embedded/bin/git \-C /var/opt/gitlab/git-data/repositories/@hashed/0b/91/0b91...f9.git gc

重新执行检查
 /opt/gitlab/embedded/bin/git \-C /var/opt/gitlab/git-data/repositories/@hashed/0b/91/0b91...f9.git fsck


重新触发仓库自检


]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>自制 USBasp</title>
    <url>/2024/07/18/mcu/make-a-usbasp-for-atmel-avr-mcu/</url>
    <content><![CDATA[
本文将 STEP BY STEP 介绍如何制作一个 USBAsp 烧录器，如果在制作过程中遇到问题，请先检查焊接是否有问题，再检查是否与本教程的操作是否有出入

准备材料
Arduino UNO
USBasp 根据 PCB 打板，并准备好上面的所有元器件
ArduinoIDE
AVRDUDE 软件
Zadig 驱动安装器
usbasp 固件

要点提醒
电路中的 3V3、68Ω 相当重要，不能随意更换为其他参数
仅支持 Atmega8、Atmega48、Atmega88 系列单片机制作 USBasp
如果你对你的焊接水平不够自信，那么最好先焊接好 USBasp 上的 Type-C 接口，然后再用万用表检查是否短路和虚焊，避免烧毁 PC 的 USB 接口

开始制作
给 Arduino UNO 烧写 ArduinoISP 程序

打开 ArduinoISP 示例代码
并将其编译上传到 Arduino UNO


将两块板子按以下表格连接



Arduino UNO
USBasp(SPI2)



5V(OUT)
VCC


GND
GND


D13
SCK


D12
MISO


D11
MOSI


D10
RST



先烧录一个测试代码以保证 USBasp 上的单片机工作没有问题

首先短接 USBASP、SELF_PROG 跳线如果是全新的芯片，有可能会无法写入，在烧录之前需要用镊子短接一下 SLOW_SCK


编译并上传 GPIO 检测代码
void setup(){  DDRC = 0xFF;  PORTC = 0xFF;}void loop(){  PORTC = 0xFE;  delay(500);  PORTC = 0xFD;  delay(500);}

等待写入完成后，PC0、PC1 这两个 IO 口连接的 LED 将会开始交替闪烁（如果没有输出，那你就得检查下焊接了）



通过 AVRDUDE 配置 USBasp

如果是全新的芯片，有可能会无法写入，在烧录之前需要用镊子短接一下 SLOW_SCK


打开 AVRDUDE，并烧录固件，我这里使用的是 Atmega8a

设置熔丝位（千万千万要小心，设置错误会导致锁芯片）

这里提供几个芯片的熔丝设置


TARGET
LFUSE
HFUSE



Atmega8
0xEF
0xC9


Atmega48
0xFF
0xDD


Atmega88
0xFF
0xDD





如果你的芯片与我使用的不一样，那就需要参考芯片手册，并在 https://www.engbedded.com/fusecalc 先尝试熔丝位设置





断开 SELF_PROG 跳线


安装驱动

断开两块板子的连接，将 USBasp 连接到 PC
打开设备管理器，没问题的话将会显示 USBasp，如果显示的是 libusb 那就需要安装驱动
打开 Zadig，在 Options 中勾选 “List ALL Devices”
在第一个下拉框中选中 libusb 设备
在驱动选择中选中 WinUSB，然后点击 Install WCID Diver
安装完成后设备管理器应该就正常显示 USBasp 了


在 ArduinoIDE 中使用 USBasp 给其他芯片烧写 bootloader

这里以 Atmega328P-AU 为例

 


题外话这块板子也可以作为最小板使用，只需要断开 USBASP 跳线，一些外围电阻、稳压管可以去掉
]]></content>
      <categories>
        <category>Programmer</category>
      </categories>
      <tags>
        <tag>MCU</tag>
        <tag>Atmel</tag>
        <tag>Arduino</tag>
        <tag>Programmer</tag>
        <tag>AVR</tag>
      </tags>
  </entry>
  <entry>
    <title>禁用 PC 版微信的图片文字识别功能</title>
    <url>/2023/08/02/other/disable-wechat-ocr/</url>
    <content><![CDATA[
自从微信增加了自动识别图片文字功能后，确实带来了一些便利，可以不用再对着截图一个字一个字敲了，但是同时也带来了不方便的地方，有些图片需要放大或拖拽时便显得不那么友好了，说到底还是制杖产品经理搞出来的反人类交互体验。

开始表演
推出微信
在资源管理器中的地址栏中输入 %AppData%，并回车
然后找到 Tencent\WeChat\XPlugin\Plugins\WeChatOCR
在 WeChatOCR 打开名称为数字的文件，然后再打开 extracted，如：WeChatOCR\7053\extracted
删除 WeChatOCR.exe
创建一个空白文本文档，将名字修改为 WeChatOCR.exe 并保存
重新打开微信，图片中的文件就不会再自动转换为文本了

]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>diss wechat</tag>
        <tag>tencent</tag>
        <tag>制杖产品</tag>
      </tags>
  </entry>
  <entry>
    <title>在 win10 上安装基于 embedded 包的 python 环境</title>
    <url>/2024/01/11/python/setup-python-with-embedded-pkg-on-win10/</url>
    <content><![CDATA[
便携可移植，啥也不说了，干就完了

安装 embedded package
安装通过 https://www.python.org/downloads/windows/ 下载最新或你需要的版本，对应的 embedded 包即可

解压

这个就不谈了，随意


配置

进入到刚才解压的目录中

找到 python&lt;version&gt;.zip 的压缩包，将其中的内容解压到 Lib 目录，没有就创建一个

修改 python&lt;version&gt;._pth，将内容修改为：
 .\Lib.\Scripts.# Uncomment to run site.main() automaticallyimport site

修改 site-packages 默认路径 创建 sitecustomize.py
 import sys

检查路径配置是否正确
 python -c "import sys;print(sys.path)"

安装 pip
 wget https://bootstrap.pypa.io/get-pip.pypython get-pip.pypython -m pip install --upgrade pip


参阅 pip documentation





]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>embedded package</tag>
        <tag>win10</tag>
        <tag>environment</tag>
      </tags>
  </entry>
  <entry>
    <title>微信小程序解包</title>
    <url>/2022/12/09/reverse/unpkg-wx-app/</url>
    <content><![CDATA[
通过解包小程序文件我们可以做一些小程序内的代码分析和资源获取

准备工作拿到 wxapkg第一步先拿到小程序的 wxapkg 文件
两种方式安卓(需要root设备)在以下目录中找到小程序包，如果不确定是哪一个，直接全部删除，然后再重新打开一遍你需要的小程序，然后再看目录下的文件
/data/data/com.tencent.mm/MicroMsg/{{user哈希值}}/appbrand/pkg/

windows(需要解密)先打开微信设置，然后找到文件管理
如下所示，然后点击打开文件夹

在打开的文件夹中再找到 Applet 文件夹并打开，就可以看到一堆小程序文件夹了，然后找到你需要的即可如果不确定是哪一个，直接全部删除，然后再重新打开一遍你需要的小程序即可
解密 wxapkg如果你是通过 windows 端获取到的 wxapkg，那么在这之前还需要进行一次解密操作
下载解密工具 https://github.com/BlackTrace/pc_wxapkg_decrypt
pc_wxapkg_decrypt.exe -wxid &lt;appid&gt; -in &lt;name&gt;.wxapkg -out &lt;path&gt;

解压 wxapkg下载解压工具 https://github.com/qwerty472123/wxappUnpacker
node wuWxapkg.js &lt;name&gt;.wxapkg

完事~
]]></content>
      <categories>
        <category>reverse</category>
      </categories>
      <tags>
        <tag>reverse</tag>
        <tag>wechat</tag>
        <tag>wxapp</tag>
        <tag>wxapkg</tag>
      </tags>
  </entry>
  <entry>
    <title>避免 SVN 每次都需要输入密码</title>
    <url>/2023/09/26/svn/svn-save-password/</url>
    <content><![CDATA[
由于每次 svn 操作都要求输入账号密码，为了优雅的使用 svn，在搜索引擎上找了一圈，全都是让你去改 config、server 文件，实际操作下来然并卵，只会浪费你的一天。原因是自从 svn 1.12 版本之后发行说明 ，就不再支持明文保存密码了。

环境
Ubuntu 20.04.6 LTS
SVN 1.13.0 (r1867053)

解决方案
由于新版本的 svn 使用了 gpg-agent 来保存秘钥信息，所以我们需要对 gpg-agent 进行配置


安装和配置 gpg-agent

安装 gpg agent
sudo apt install gnupg-agent

安装 pinentry-tty

pinentry-tty 是更简单的文本界面

sudo apt install pinentry-ttyecho "pinentry-program /usr/bin/pinentry-tty" &gt;&gt; ~/.gnupg/gpg-agent.confgpg-connect-agent reloadagent /bye


修改 .profile 文件，将以下内容添加到文件尾部
 export GPG_TTY=$(tty)

 保存后执行 . ~/.profile 使配置生效

删除 svn 已保存的认证信息
 rm -rf ~/.subversion/auth

 重新执行 svn 操作，会提示你输入用户密码，同时 GPG-Agent 会缓存密码，下次操作时就不需要再次输入密码了

修改缓存过期时间

由于 gpg-agent 会将秘钥缓存，那既然是缓存，那肯定会过期，所以我们还要修改 gpg-agent 的配置，来延长缓存有效期，但是重启系统后还是会失效

 修改 ~/.gnupg/gpg-agent.conf 文件，添加以下内容 注意：这将会降低安全性
 default-cache-ttl 0 # 缓存时间，0 表示永久max-cache-ttl 0

]]></content>
      <categories>
        <category>svn</category>
      </categories>
      <tags>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title>at 命令</title>
    <url>/2022/10/18/ubuntu/at/</url>
    <content><![CDATA[
at 命令可以将某些命令或任务放到指定的时间自动执行

TIPS
at 命令与 jobs 命令有所不同，当登录用户退出后 jobs 命令的任务会被取消，而 at 命令则不会

命令说明-V 输出版本号-f 指定脚本文件-l 查看查看任务队列，等同于atq-d 删除指定任务，等同于atrm-r 删除指定任务，等同于atrm-c 打印任务的内容到标准输出atrm 删除指定任务atq 查看任务队列

使用创建指定时间执行命令的任务
~ at 17:13 # 设定当时间到达 17:13 时at&gt; echo "hello" &gt;&gt; a # 将 `hello` 输出到 a 文件中at&gt; &lt;EOT&gt; # 按下 `ctrl+d` 创建任务job 9 at Tue Oct 18 17:13:00 2022 # 返回任务 id 为 9 并将在指定的时间执行该任务

创建指定时间执行脚本的任务
at -f upload.sh 17:13

或者也可以使用立即执行的方式来实现等同于 &amp; 的效果
at -f upload.sh now
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shell</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu20.04 桌面版转换为服务器版</title>
    <url>/2025/01/01/ubuntu/desktop-convert-server/</url>
    <content><![CDATA[
闲来无事瞅了一眼平时拿来做服务器的主机，发现硬盘灯一直常亮，看了一下占用，发现是 /usr/bin/gnome-shell 占用了大量的内存，同时还有 20MB/s 的读写速度。因为之前这台机器是作为桌面开发环境使用的，所以直接安装了桌面版的 Ubuntu 20.04，现在主要是作为服务器使用，所以我将其转换为服务器版本。

环境描述
Ubuntu 20.04.3 LTS

转换步骤
安装 server
 sudo apt install ubuntu-serversudo reboot

设置默认用户界面

设置为终端模式
  sudo systemctl set-default multi-user.targetsudo reboot

设置为图形模式
  sudo systemctl set-default graphical.targetsudo reboot


移除桌面依赖软件包

如果后期还想使用桌面版，则不要进行这一步操作，只需要执行上一步的设置为图形模式即可恢复桌面环境。

 sudo apt purge ubuntu-desktop -y &amp;&amp; sudo apt autoremove -y &amp;&amp; sudo apt autoclean# 可选sudo apt purge xorg-docs-core xorg xserver-*sudo reboot


在移除后可以使用以下命令再检查一下是否还有残留的软件包
  sudo apt list --installed

  这里给出一些软件包，可以根据名称过滤一下
  ubuntu-minimal-desktop ubuntu-advantage-desktop-daemon ubuntu-docs ubuntu-mono ubuntu-release-upgrader-gtk ubuntu-report ubuntu-session ubuntu-wallpapers-jammy ubuntu-wallpapers




]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu server</tag>
        <tag>ubuntu desktop</tag>
      </tags>
  </entry>
  <entry>
    <title>jobs 命令</title>
    <url>/2022/10/18/ubuntu/jobs/</url>
    <content><![CDATA[
jobs是Linux命令。jobs命令显示了当前shell环境中已启动的作业状态。如果JobID参数没有指定特定作业，就显示所有的活动的作业的状态信息。如果报告了一个作业的终止，shell从当前的shell环境已知的列表中删除作业的进程标识。


job 命令通常与 wait、fg、bg、kill 命令一起使用

示例
命令挂起

使用 wget 下载一个文件 $ wget ${remote_file} .
然后在下载过程中按下 ctrl+z 将任务挂起 downloading...^Z # 这时按下了 `ctrl+z`[1]  + 140578 suspended  wget ${remote_file} . # 下载任务被挂起，任务 id 为 1
通过 jobs -l 查看被挂起的任务 $ jobs -l[1]  + 140578 suspended  wget ${remote_file} . # 有一个 id 为 1 的任务 pid 为 140578


将任务通过 fg 恢复到前台继续执行
 $ fg %1 # % 是必须的，%1 标识任务 id 为 1 的任务[1]  + 140578 continued  wget ${remote_file} .downloading... # 下载任务已经恢复到前台并继续下载
 这时我们仍然可以再次使用 ctrl+z 将任务挂起

其他 bg、wait、kill 与 fg 的使用方式类似，都是通过 %{任务id} 的方式进行对任务的操作，这里就不再过多讨论


]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shell</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Ubuntu 中用命令行查看流量占用</title>
    <url>/2022/10/18/ubuntu/nethogs/</url>
    <content><![CDATA[
使用 nethogs 工具，我们可以 top 命令一样查看网卡\进程的流量占用情况

安装sudo apt install nethogs

运行sudo nethogs


如果没有报错的话你就会看到下面的界面

命令说明-V : 显示版本-h : 显示帮助信息-b : 比 -t 更为详细的跟踪模式-d : 数据刷新时间 如 nethogs -d 1 就是每秒刷新一次-v : 查看模式(0 = KB/s, 1 = 显示总流量单位KB, 2 = 显示总流量单位B, 3 = 显示总流量单位MB). 默认为 0.-c : 刷新次数-t : 跟踪模式在 nethogs 运行过程中按下(类似 top 快捷键):q: 退出s: 按发送流量排序r: 按接收流量排序m: 切换查看模式 -v
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 添加硬盘并分区</title>
    <url>/2024/09/23/ubuntu/new-disk-partition-gpt-ext4/</url>
    <content><![CDATA[
本教程将教会你如何在 Ubuntu 下如何对新加硬盘分区并挂载我使用了一块 1T 的东芝机械硬盘，所以本文将使用 GPT 分区表 + EXT4 文件系统的方式操作新硬盘

知识扩展GPT（GUID Partition Table）
用途：一种分区表布局，用来管理硬盘的分区。它是MBR（Master Boot Record）的现代替代方案。
特性：
支持大容量硬盘，最高支持 18EB（1EB = 1024PB）。
每个硬盘上可以有 128个以上的主分区（MBR只支持4个主分区）。
GPT 分区更安全，每个分区表都有备份，并且有 CRC 校验防止分区表损坏。
必须在 UEFI 启动模式 下使用。



EXT4（Fourth Extended Filesystem）
用途：一种文件系统，通常用于 Linux 环境中存储和管理文件。
特性：
是 EXT 文件系统系列的第四代，提供了更高的性能和可靠性。
支持单个文件大小最大为 16TB，整个文件系统最大可以达到 1EB。
提供更好的碎片管理、延迟分配（Delayed Allocation）、日志记录功能（Journaling），使其在性能和数据安全性上有较大提升。
与较老的 EXT3 文件系统向后兼容。



友情提示!!! 数据无价，请谨慎操作 !!!
!!! 数据无价，请谨慎操作 !!!
!!! 数据无价，请谨慎操作 !!!
分区表
确认新加硬盘名称
 首先，使用 lsblk 或 fdisk -l 命令来列出当前系统中的硬盘设备，并确认要处理的硬盘名称（通常是 /dev/sdX，X 代表硬盘的字母编号，如 /dev/sdb）。
 lsblk

 可能有如下输出，这里 sdb 就是我新加硬盘的名称
 NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTsda      8:0    0 931.5G  0 disk├─sda1   8:1    0 139.7G  0 part /└─...sdb      8:16   0 931.5G  0 disk

创建 GPT 分区表
 sudo gdisk /dev/sdb

 进入 gdisk 后，按以下顺序操作：

输入 o 清除现有的分区表并创建一个新的 GPT 分区表。
输入 w 保存并退出。



操作分区
创建默认分区

我这里直接全盘分一个区，如果你要分多个区也是类似操作，只是需要修改分区号和起始和结束扇区，这里不再赘述

 sudo gdisk /dev/sdb

 进入 gdisk 后：

输入 n 来创建一个新分区。
按回车键接受默认的分区号。
输入分区的起始扇区和结束扇区，通常默认值是从磁盘的开头到结尾，这样可以使用整个硬盘。
输入 w 保存并退出。


设置分区的文件系统格式
 将刚才创建的 /dev/sdb1 分区的文件系统格式设置为 ext4
 sudo mkfs.ext4 /dev/sdb1

挂载分区
 sudo mkdir -p /storagesudo mount /dev/sdb1 /storage

自动挂载
查看分区信息
 sudo blkid /dev/sdb1

 记录下 UUID=xxxxx 等号后面的内容，写到下面的 fstab

修改 fstab
 sudo vim /etc/fstab

 在文件末尾添加
 UUID=xxxxxxxxx /storage ext4 defaults 0 2

为了防止手抖写错，验证一下
 sudo mount -a

]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shell</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>rsync 命令</title>
    <url>/2022/10/18/ubuntu/rsync/</url>
    <content><![CDATA[
rsync 全称 Remote Sync.rsync是linux系统下的数据镜像备份工具。使用快速增量备份工具Remote Sync可以远程同步，支持本地复制，或者与其他SSH、rsync主机同步。

常用参数-v, --verbose 详细模式输出-q, --quiet 精简输出模式-c, --checksum 打开校验开关，强制对文件传输进行校验-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD-r, --recursive 对子目录以递归模式处理-R, --relative 使用相对路径信息-b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。--backup-dir 将备份文件(如~filename)存放在在目录下。-suffix=SUFFIX 定义备份文件前缀-u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件)-l, --links 保留软链结-L, --copy-links 想对待常规文件一样处理软链结--copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结--safe-links 忽略指向SRC路径目录树以外的链结-H, --hard-links 保留硬链结-p, --perms 保持文件权限-o, --owner 保持文件属主信息-g, --group 保持文件属组信息-D, --devices 保持设备文件信息-t, --times 保持文件时间信息-S, --sparse 对稀疏文件进行特殊处理以节省DST的空间-n, --dry-run现实哪些文件将被传输-W, --whole-file 拷贝文件，不进行增量检测-x, --one-file-system 不要跨越文件系统边界-B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节-e, --rsh=COMMAND 指定使用rsh、ssh方式进行数据同步--rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件--existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件--delete 删除那些DST中SRC没有的文件--delete-excluded 同样删除接收端那些被该选项指定排除的文件--delete-after 传输结束以后再删除--ignore-errors 及时出现IO错误也进行删除--max-delete=NUM 最多删除NUM个文件--partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输--force 强制删除目录，即使不为空--numeric-ids 不将数字的用户和组ID匹配为用户名和组名--timeout=TIME IP超时时间，单位为秒-I, --ignore-times 不跳过那些有同样的时间和长度的文件--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0-T --temp-dir=DIR 在DIR中创建临时文件--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份-P 等同于 --partial--progress 显示备份过程-z, --compress 对备份的文件在传输时进行压缩处理--exclude=PATTERN 指定排除不需要传输的文件模式--include=PATTERN 指定不排除而需要传输的文件模式--exclude-from=FILE 排除FILE中指定模式的文件--include-from=FILE 不排除FILE指定模式匹配的文件--version 打印版本信息--address 绑定到特定的地址--config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件--port=PORT 指定其他的rsync服务端口--blocking-io 对远程shell使用阻塞IO-stats 给出某些文件的传输状态--progress 在传输时现实传输过程--log-format=formAT 指定日志文件格式--password-file=FILE 从FILE中得到密码--bwlimit=KBPS 限制I/O带宽，KBytes per second-h, --help 显示帮助信息

示例
从 remote 断点续传 xxx.tar 到当前目录
  rsync -P --rsh=ssh remote:xxx.tar .

从 remote 传输目录 /xxx/xxx 到当前目录
  rsync -r --rsh=ssh remote:/xxx/xxx .

]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shell</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>scp 命令</title>
    <url>/2022/10/18/ubuntu/scp/</url>
    <content><![CDATA[
Linux scp 命令用于 Linux 之间复制文件和目录。scp 是 secure copy 的缩写, scp 是 linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令。scp 是加密的，rcp 是不加密的，scp 是 rcp 的加强版。

常用参数-B 使用批处理模式（传输过程中不询问传输口令或短语）-C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能）-p 保留原文件的修改时间，访问时间和访问权限。-q 不显示传输进度条。-r 递归复制整个目录。-v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。-l limit 限定用户所能使用的带宽，以Kbit/s为单位。-P port：注意是大写的P, port是指定数据传输用到的端口号

示例
从本地复制到远程

复制单个文件
  scp xx.txt root@remote:/scp xx.txt remote:/

复制目录
  scp -r dir remote:/


从远程复制到本地  将参数顺序颠倒即可

指定端口
  scp -P 3301 xx.txt remote:/

]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shell</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>script 命令</title>
    <url>/2022/10/25/ubuntu/script/</url>
    <content><![CDATA[
有时我们需要在脚本中加入一些有进度状态的命令，为了既能让我们的脚本无需人工守候，又能方便的监测到这些命令的执行情况时，就该 script 登场了

常用参数-a 以追加的形式，将命令的执行状态输出到指定的文件中-c 运行指定命令-q 让 -c 指定的命令以静默方式运行，比如删除文件时的确认提示

使用示例
记录 scp 过程
  script -q -a record.log -c "scp xxx.zip remote:/"

最后当然 script 能做到的不止这些，你还可以使用该命令去记录每个 shell 用户的所有操作，等等
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shell</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh 实现指定用户仅认证不登录</title>
    <url>/2022/11/15/ubuntu/ssh-no-login/</url>
    <content><![CDATA[
当我们有 ssh 代理代理转发的需求时，就可以在跳板机上做一个仅任认证不登录的用户，用来防止跳板机被以外登录

创建用户sudo adduser jump

配置 sshd先切换到 jump 用户
欢迎信息vim /home/jump/banner
Ok! You've successfully authenticated.

创建 authorized_keysmkdir /home/jump/.ssh &amp;&amp; chmod 755 /home/jump/.sshvim /home/jump/.ssh/authorized_keys

将公钥添加到 authorized_keys 文件中
修改 sshd_configsudo vim /etc/ssh/sshd_config

将下面的内容添加到 sshd_config 文件末尾
Match User jump  Banner /home/jump/banner  AuthorizedKeysFile /home/jump/.ssh/authorized_keys  PasswordAuthentication no  PubkeyAuthentication yes

重启 sshd/etc/init.d/ssh restart

到这里就可以通过正常的 ssh 方式登录 jump 用户了，而且登录时第一行会看到 banner 文件中的内容
修改 shell (禁用登录)vim /etc/passwd
找到 jump，将最后的 /bin/bash 改为 /bin/false
现在再通过 ssh 的方式登录，会先登录成功，然后紧接着就被关闭连接
到这里就已经基本实现了仅认证不登录的实现
优化部分去除登录后显示的系统信息登录信息在登录成功后默认会展示一大堆内容，这些是不需要的，所以如何隐藏它？
很简单，直接在 jump 用户目录下创建一个 .hushlogin 文件即可
touch /home/jump/.hushlogin

然后再通过 ssh 登录就看不到默认输出的一大堆内容了，就只会看到 banner 文件中的内容
优化显示登录信息如果只想显示登录信息改如何修改？
还是先按照上面的内容，通过创建 .hushlogin 文件去除默认信息
然后再通过创建 rc 文件
vim /home/jump/.ssh/rc

将以下内容写入到 rc 文件中
lastlog -u $USER | perl -lane 'END{print "Last login: @F[3..6] $F[8] from $F[2]"}'

再通过 ssh 登录，就只会看到上一次的登录信息了
]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu Server 2204配置无线网卡</title>
    <url>/2023/09/15/ubuntu/usb-net/</url>
    <content><![CDATA[
本文主要介绍如何在 Ubuntu Server 2204 上配置无线网卡，以及如何安装驱动。

环境描述
System: Ubuntu 22.04.3 LTS
USB Network Adapter: Realtek Semiconductor Corp. RTL8192EU 802.11b/g/n WLAN Adapter

查看网卡信息这一步是为了确认网卡型号，以及是否被系统识别。
lsusb

这里应该会列出一大堆硬件设备，无需理会其他的，我们只关注 WLAN Adapter 结尾的，如下图所示：

如果没有找到，那么有三种可能：一是 USB 口的问题，换一下 USB 口；二是网卡损坏了，这个换台 Windows 机器就能判断；三是网卡模式不对，这个可以 切换网卡模式。

接下来，我们需要查看各个网卡的名称，等下在配置网络的时候会用到。
ip a show

结果如下
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: enp4s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000    link/ether 08:60:6e:45:c1:64 brd ff:ff:ff:ff:ff:ff    inet 192.168.1.106/24 brd 192.168.1.255 scope global enp4s0       valid_lft forever preferred_lft forever    inet6 fe80::a60:6eff:fe45:c164/64 scope link       valid_lft forever preferred_lft forever3: enp5s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc fq_codel state DOWN group default qlen 1000    link/ether 08:60:6e:45:c1:65 brd ff:ff:ff:ff:ff:ff4: enp6s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc fq_codel state DOWN group default qlen 1000    link/ether 08:60:6e:45:c1:66 brd ff:ff:ff:ff:ff:ff5: enp7s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc fq_codel state DOWN group default qlen 1000    link/ether 08:60:6e:45:c1:67 brd ff:ff:ff:ff:ff:ff6: wlx30b49eb80805: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc mq state DOWN group default qlen 1000    link/ether 30:b4:9e:b8:08:05 brd ff:ff:ff:ff:ff:ff

查看驱动信息sudo lshw -C network

找到描述为 description: Wireless interface 的一项，然后看 configuration -&gt; driver 是否显示为 rtl8xxxu，如果是的话，说明系统已经自动加载了驱动，可以跳过下面的步骤，直接进行 网络配置。
网络配置编辑网络配置文件sudo vim /etc/netplan/00-installer-config.yaml

将文件内容修改为如下：
network:  version: 2  renderer: networkd # 渲染器  wifis:    # 无线网卡    wlx30b49eb80805: # USB网卡的名称，可通过 ip a 命令查看      dhcp4: yes # 是否为Ipv4动态分配地址      optional: true # 是否可选      access-points:        "wifi-name": # wifi名称          password: "wifi-password" # wifi密码    # 有线网卡，按你的实际情况配置    enp4s0: # 有线网卡的名称，可通过 ip a 命令查看      dhcp4: no      dhcp6: no # 是否为Ipv6动态分配地址      optional: true      addresses: # 静态IP地址        - 192.168.1.106/24 # IP地址/子网掩码      nameservers: # DNS服务器地址        addresses: # DNS服务器地址列表          - 223.5.5.5 # DNS服务器地址          - 223.6.6.6 # DNS服务器地址          - 192.168.1.1 # DNS服务器地址      routes: # 路由        - to: default # 默认路由          via: 192.168.1.1 # 默认路由的网关    enp5s0:      dhcp4: no      dhcp6: no      optional: true    enp6s0:      dhcp4: no      dhcp6: no      optional: true    enp7s0:      dhcp4: no      dhcp6: no      optional: true

重启网络服务先进行配置检查
sudo netplan try

没问题的话直接敲回车确认，然后会自动应用新配置。
查看网络状态等待一会儿，再次查看网络状态
ip a show

如果看到 wlx30b49eb80805 这个网卡的状态为 UP，并且有 inet 的地址，说明配置成功了,那么到这里就结束了。

但是
如果没有 inet 的地址，可以尝试重启网络服务，或者重启系统。但是如果在重启之后，还是没有 inet 的地址，那么大概率是驱动的问题，可以尝试安装驱动。

安装驱动安装依赖sudo apt-get install git linux-headers-generic build-essential dkms

下载驱动git clone https://github.com/Mange/rtl8192eu-linux-driver

编译并安装cd rtl8192eu-linux-driversudo dkms add .sudo dkms install rtl8192eu/1.0

将系统自带驱动加入黑名单echo "blacklist rtl8xxxu" | sudo tee /etc/modprobe.d/rtl8xxxu.conf

系统启动时自动加载 rtl8192eu 驱动echo -e "8192eu\n\nloop" | sudo tee /etc/modules

避免新版系统热插拔后失效echo "options 8192eu rtw_power_mgnt=0 rtw_enusbss=0" | sudo tee /etc/modprobe.d/8192eu.conf

更新Grub和initramfssudo update-grub &amp;&amp; sudo update-initramfs -u

重启 systemctl 以重新生成 initramfssystemctl reboot -i

查看驱动是否被正确加载sudo lshw -C network

找到描述为 description: Wireless interface 的一项，然后看 configuration -&gt; driver 是否显示为 8192eu，如果是的话，说明驱动加载成功，直接进行 网络配置。
一些其他的问题无法连接到wifi需要检查下无线网卡是否启用，可以通过 ip a show 查看，如果没有 UP 的状态，可以通过 sudo ip link set wlx30b49eb80805 up 启用。
切换网卡模式通过 lsusb -t 查看，如果是 Mass Storage 模式，那么就需要切换模式了，这个可以通过 sudo usb_modeswitch -KW -v 0bda -p 1a2b 来切换，其中 0bda 和 1a2b 是网卡的厂商ID和产品ID，可以通过 lsusb 查看。
重启后失效，可以通过修改 /usr/lib/udev/rules.d/40-usb_modeswitch.rules 文件来解决。
# Realtek RTL8192EU Wifi AC USBATTR{idVendor}=="0bda", ATTR{idProduct}=="1a2b", RUN+="/usr/sbin/usb_modeswitch -KW -v 0bda -p 1a2b"
]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>RTL8192EU</tag>
        <tag>wlan adapter</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>用户与用户组</title>
    <url>/2023/07/20/ubuntu/user-group/</url>
    <content><![CDATA[
对 Linux 用户及用户组进行管理与修改

Tools
adduser - 添加用户
userdel - 删除用户
addgroup - 添加组
groupdel - 删除组
usermod - 修改用户组
id - 查看用户信息

Commend用户
添加用户
adduser app

删除用户
userdel -r app

查看用户信息
id app

组
添加组
addgroup app-group

删除组
groupdel app-group

修改用户组
# 会删除 app 用户原本的组usermod -G app-group app# 将 app-group 添加到 app 用户的现有组列表中usermod -a -G app-group app# 或者使用以下命令gpasswd -a app app-group# 修改 app 用户登录 shellusermod -s /bin/false app

在用户现有组基础上添加其他组
usermod -a -G adm,dialout,cdrom,floppy,sudo,audio,dip,video,plugdev,netdev,lxd ubuntu

]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>shell</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>安装及配置 v2ray</title>
    <url>/2023/04/21/tools/v2ray-install-setup/</url>
    <content><![CDATA[
基于 ubuntu 22.04 搭建 Nginx + TLS + VMess + WebSocket + HTTP/2

前提
墙外 VPS

安装基础环境
安装 V2ray

bash &lt;(curl -L https://raw.githubusercontent.com/v2fly/fhs-install-v2ray/master/install-release.sh)


安装 Nginx

apt install nginx

配置 V2ray 服务
添加用户

useradd -s /usr/sbin/nologin v2ray


自动启动

systemctl enable v2ray


修改服务启动用户

vim /etc/systemd/system/v2ray.service

添加以下内容
[Service]User=v2ray

配置 Nginx + TLS
创建 Nginx 配置

vim /etc/nginx/sites-available/example.com.conf
将以下内容粘贴到文件中
server {        listen 80;        listen [::]:80;        root /var/www/html;        # Add index.php to the list if you are using PHP        index index.html index.htm index.nginx-debian.html;        server_name example.com;        location / {                # First attempt to serve request as file, then                # as directory, then fall back to displaying a 404.                try_files $uri $uri/ =404;        }}


启用配置

ln -s /etc/nginx/sites-available/example.com.conf /etc/nginx/sites-enabled/example.com.confnginx -tnginx -s reload


配置 SSL 证书

# 安装 acme.shcurl https://get.acme.sh | sh -s email=my@example.com# 生成证书并验证域名acme.sh --issue -d example.com --nginx# 安装证书acme.sh --install-cert -d example.com \--key-file       /path/to/keyfile/in/nginx/key.pem  \--fullchain-file /path/to/fullchain/nginx/cert.pem \--reloadcmd     "service nginx force-reload"# 查看证书acme.sh --info -d example.com


配置 Nginx + TLS

将以下内容添加到 Nginx 配置文件
server {    listen 443 ssl;    listen [::]:443 ssl;    root /var/www/html/;    ssl_certificate       /root/.acme.sh/example.com_ecc/fullchain.cer;    ssl_certificate_key   /root/.acme.sh/example.com_ecc/example.com.key;    ssl_session_timeout 1d;    ssl_session_cache shared:MozSSL:10m;    ssl_session_tickets off;    ssl_protocols         TLSv1.2 TLSv1.3;    ssl_ciphers           ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;    ssl_prefer_server_ciphers off;    server_name           example.com;    location /vvray {        if ($http_upgrade != "websocket") {            return 404;        }        proxy_redirect off;        proxy_pass http://127.0.0.1:12345;        proxy_http_version 1.1;        proxy_set_header Upgrade $http_upgrade;        proxy_set_header Connection "upgrade";        proxy_set_header Host $host;        # Show real IP in v2ray access.log        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    }}


重新加载 Nginx 配置

nginx -tnginx -s reload

启动 V2ray
配置文件

vim /usr/local/etc/v2ray/config.json

将以下内容添加到文件中
{  "log": {    "loglevel": "warning"  },  "inbounds": [    {      "listen": "127.0.0.1", // 不再向外直接开放      "port": 12345, // 与 nginx 反向代理端口一致      "protocol": "vmess",      "settings": {        "clients": [          {            "id": "xxx" // 可通过 v2ray uuid 命令生成          }        ]      },      "streamSettings": {        "network": "ws",        "wsSettings": {          "path": "/vvray" // 与 nginx 反向代理一致        }      }    }  ],  "outbounds": [    {      "protocol": "freedom"    }  ]}


启动服务

systemctl start v2ray

客户端
clash 配置

proxies:  - name: 'xxx'    type: vmess    server: example.com    port: 443    uuid: 43cb6fce-a840-a468-afe5-99151333b8dd    alterId: 0    cipher: auto    tls: true    skip-cert-verify: true    network: ws    ws-opts:      path: /vvray    # headers: # 按需配置    #   Host: example.com    #   User-Agent: 'xxx'
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>v2ray</tag>
        <tag>clash</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title>AMD VMware Workstation 15.1 安装 MacOS Catalina 10.15.5</title>
    <url>/2023/04/13/vmware/amd-vmware15.1-install-macos-10.15.x/</url>
    <content><![CDATA[
辣鸡 MacBook，配置低不说，还卖得贼拉贵，所以我等穷鬼只能走歪门邪道。。。真香

前提条件
有一台强大的物理机，具体多强？看下面，如果达不到要求，直接劝退
CPU: AMD 主频 4.0 GHz 以上
MEM: 16G 以上，建议 32G 更好
DISK: 可用空间至少 300G 以上，固态最好


VMware Workstation 15.1.0
Unlocker - 解锁工具，让 VMware 可以安装 MacOS
macOS 10.15.5 镜像

安装 VMware Workstation
这个就不说了，太过简单

安装 UnlockerUnlocker 下载地址 https://github.com/theJaxon/unlocker
你说 archived？自己想办法
找到可用的库，然后克隆到本地
先结束掉所有 VMware 的进程
然后打开 Unlocker 目录，找到 win-install.cmd，右键 以管理员身份运行，这一步必须要网好，否则会很慢很慢
完成后会自动关闭窗口

创建虚拟机启动 VMware，创建新的虚拟机，在系统选择那里会看到多出了一个 Apple Mac OS 的选项，选中后选择对应的系统版本
后面的操作都是正常操作就不再赘述了，在创建完成后先不要启动，还需修改一些文件配置
修改虚拟机配置
修改 vmx 文件进入刚才创建的虚拟机目录，找到后缀为 vmx 的文件

打开 vmx
找到 virtualHW.version = "16" 修改为 virtualHW.version = "10"

找到 smc.version （如没有则新增一个就行）修改为 smc.version = "0"
并增加以下内容
cpuid.0.eax = "0000:0000:0000:0000:0000:0000:0000:1011"cpuid.0.ebx = "0111:0101:0110:1110:0110:0101:0100:0111"cpuid.0.ecx = "0110:1100:0110:0101:0111:0100:0110:1110"cpuid.0.edx = "0100:1001:0110:0101:0110:1110:0110:1001"cpuid.1.eax = "0000:0000:0000:0001:0000:0110:0111:0001"cpuid.1.ebx = "0000:0010:0000:0001:0000:1000:0000:0000"cpuid.1.ecx = "1000:0010:1001:1000:0010:0010:0000:0011"cpuid.1.edx = "0000:1111:1010:1011:1111:1011:1111:1111"

启动虚拟机启动完成后，则进入到 macOS 的安装中
之前的内容都没什么特别，直到使用 磁盘工具 进行分区时我们会发现键盘无法输入
这时需要通过将键盘切换到虚拟机才能对分区进行命名操作，然后我们继续安装
在正式进入到安装并读条时，肯定会安装失败，然后会自动跳到 ‘macOS实用工具’ 界面，这里我们直接关闭客户机即可
然后打开 编辑虚拟机设置，按下图修改，在修改过程中会弹出警告，点击确定关闭掉即可，最后保存设置，然后再重新启动虚拟机

重新启动虚拟机后，我们便可以继续进行系统安装，最后就可以正常使用了
]]></content>
      <categories>
        <category>vmware</category>
      </categories>
      <tags>
        <tag>vmware</tag>
        <tag>MacOS Catalina 10.15.x</tag>
        <tag>黑苹果</tag>
        <tag>真香系列</tag>
        <tag>AMD yyds</tag>
      </tags>
  </entry>
  <entry>
    <title>如何优雅地让特定应用程序绕过用户帐户控制通知弹窗</title>
    <url>/2023/05/06/windows/bypass-user-account-control-notifications/</url>
    <content><![CDATA[
我们在使用 Windows 系统时，在打开一些应用程序时，经常会看到 “用户账户控制” 的对话框，有些甚至会将屏幕背景变暗，非常不舒适，本教程可以让你对特定（你完全信任）的应用跳过这个弹窗提示，十分优雅~

找到应用程序可执行文件直接右键应用快捷方式，然后点击 “属性”
然后把 “目标” 里面的内容保存下来，后面会用到
创建以管理员权限运行的任务右键点击我的电脑，打开 “管理”
按顺序依次展开 计算机管理 -&gt; 系统工具 -&gt; 任务计划程序 -&gt; 任务计划程序库
然后在 “任务计划程序库” 上点击右键，点击 “新建文件夹”，名称输入你应用程序的名称即可
然后点击刚才创建的文件夹，在文件夹上点击右键，打开 “创建任务”
常规选项卡配置在弹出的创建任务对话框中，打开常规选项卡，勾选最下面的 “使用最高权限运行”（即管理员权限运行），如下图

触发器配置
这一步一般是用来配置启动时自动运行，如果不需要则可以跳过这一步

打开触发器选项卡，点击新建，然后如下图配置即可

操作配置
重点

打开操作选项卡，点击新建，操作选择 “启动程序”，程序或脚本中输入之前我们在 找到应用程序可执行文件 这一步保存的内容即可
最后右键刚才创建好的任务，点击属性，将 “位置” 和 “名称” 复制并按格式组合起来 位置\名称，然后保存备用
最后点击创建任务对话框的确定按钮，到这里我们就完成了任务的创建
配置快捷方式
如果在 触发器配置 配置了自动运行，则可以不需要这一步

在桌面上点击右键，新建 -&gt; 快捷方式
在输入框中输入以下内容，”xxxxxxx” 替换为在 最后 组合的内容
C:\Windows\System32\schtasks.exe /RUN /TN "xxxxxxx"

然后点击下一步
在输入框中写入应用程序的名称，点击完成
稍微美化一下
其实到这里基本上已经基本上已经完成了配置，如果不想再搞的童鞋就可以结束了

右键点击刚才创建好的快捷方式，点击属性
然后在 “快捷方式” 选项卡中点击更改图标，然后找到应用程序(.exe)，保存即可
]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>User Account Control Notifications</tag>
        <tag>Windows 小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>WSL 通过 adb 连接宿主机下的安卓设备</title>
    <url>/2025/10/16/wsl/adb-connect-host-android-device/</url>
    <content><![CDATA[
本教程将会教你如何在不修改 wsl 内核和不安装多余的插件的情况下通过 ssh 创建隧道再通过 adb 连接宿主机下的 android 设备

环境说明
宿主机: Windows 10 (19045.5608)
wsl: Ubuntu 24.04.3 LTS

必备知识
首先学习一下 adb 的工作方式, adb 采用 客户端&lt;-&gt;服务端&lt;-&gt;设备 的架构


adb server: 服务端, 这是一个在 PC 上长期运行的后台进程, 当执行 adb 命令时都会先与该服务通信
adb daemon: 守护进程(adbd), 该进程是在 android 设备上运行的后台进程
adb client: 客户端, 这是我们在 PC 上执行 adb 命令时调用的程序, 每当执行一条该命令, 都是一个独立的客户端
5037 端口: adb server 通信端口(这个端口是由 Android 开源项目在最初设计时人为指定的, 为了避免与其他常见服务冲突而规定的端口)

原理
通过 ssh 将 wsl 中的 5037 端口转发到宿主机的 0.0.0.0:5037 端口, 从而实现 wsl 中的 adb client 连接到 windows 的 adb server, 通过 ssh 转发后相当于直接将 wsl 的端口绑定到宿主机了, 宿主机连接了哪些设备, 相应的, wsl 中的 adb server 也连接了这些端口

必要环境在 wsl 中执行以下命令
sudo apt install openssh-serversudo service ssh restart

创建 SSH 转发隧道在 windows 中执行以下命令
ssh -R 0.0.0.0:5037:127.0.0.1:5037 &lt;wsl_user&gt;@&lt;wsl_ip&gt; -f -N

命令分解
-R
这是关键参数，表示远程端口转发（Reverse tunneling）：

本地机器：SSH 客户端所在的机器（执行命令的地方）
远程机器：SSH 服务器所在的机器（username@wsl_ip）


0.0.0.0:5037:127.0.0.1:5037
这个格式是 [远程绑定地址]:[远程端口]:[本地地址]:[本地端口]

0.0.0.0:5037（远程端）：
0.0.0.0：在远程机器上监听所有网络接口
5037：在远程机器上打开的端口

127.0.0.1:5037（本地端）：
127.0.0.1：本地回环地址（localhost）
5037：本地机器上的 ADB Server 端口



&lt;wsl_user&gt;@&lt;wsl_ip&gt;
ssh 连接的目标机器和用户

wsl_user: wsl 中的用户名
wsl_ip: wsl 的 IP 地址


-f
后台运行

-N
不执行远程命令，只建立隧道


数据流向图解  远程机器 (WSL)                     本地机器 (Windows)       ↓                                   ↓  0.0.0.0:5037     ←→ SSH隧道 ←→     127.0.0.1:5037  (监听所有接口)                        (ADB Server)       ↑                                   ↑WSL中的ADB Client                  Windows中的ADB Server

可能遇到的问题
创建隧道后，wsl 还是无法访问到设备：
在 wsl 执行 adb kill-server 再重试 adb devices

如何关闭该隧道

选其一即可


在 Windows 的任务管理器中找到名称为 ssh 的任务，终止
在 CMD 中输入 taskkill /F /IM ssh.exe
在 WSL 中输入 pkill sshd



]]></content>
      <categories>
        <category>wsl</category>
      </categories>
      <tags>
        <tag>wsl</tag>
        <tag>adb</tag>
      </tags>
  </entry>
</search>
